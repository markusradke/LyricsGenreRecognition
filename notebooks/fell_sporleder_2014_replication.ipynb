{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947dee26",
   "metadata": {},
   "source": [
    "## Fell + Spohrleder (2014) n-gram Baseline Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "english = pd.read_csv(\"../data/poptrag_lyrics_genres_corpus_filtered_english.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c011e",
   "metadata": {},
   "source": [
    "### Preprocessing and n-gram Feature Extraction\n",
    "1. extract unigram, bigram, and trigram features from the lyrics\n",
    "- make lowercase, remove punctuation (except apostrophes)\n",
    "- contractions like \"don't\" should not be split during tokenization\n",
    "2. calculate n-gram tf-idf for all n-grams with genres (cat[n]) as documents (frequency +1 per tracks that contiain the n-gram) \n",
    "3. rank all n-grams by tf-idf score within each genre\n",
    "4. \"downrank artist specific ngrams\" by removing n-grams that occur in less than x? (e.g, 50) different artists\n",
    "5. per genre and n, select top 100 n-grams as binary features (present / not present in lyrics) (produces 2700 features max for 9 genres; might be less due to overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6dc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting n-grams from all lyrics...\n",
      "\n",
      "============================================================\n",
      "✓ Extracted unigrams:\n",
      "  - Number of unique unigrams: 108,604\n",
      "  - Matrix shape: (111938, 108604)\n",
      "  - Example unigrams: ['shully', 'cape', 'allair', \"ubangi's\", 'freaky']\n",
      "✓ Extracted bigrams:\n",
      "  - Number of unique bigrams: 2,052,265\n",
      "  - Matrix shape: (111938, 2052265)\n",
      "  - Example bigrams: ['pour smell', 'box city', 'alight just', 'skynyrd tunes', 'faithless night']\n",
      "✓ Extracted trigrams:\n",
      "  - Number of unique trigrams: 6,582,416\n",
      "  - Matrix shape: (111938, 6582416)\n",
      "  - Example trigrams: ['the twilight in', 'cafés in the', 'aisles fill again', 'wishing wishing further', 'her beauty like']\n",
      "Calculating tf-idf for combinations of n-grams and G5 genres...\n",
      "\n",
      "============================================================\n",
      "Calculating genre-level TF-IDF for unigrams with cat5 genres ...\n",
      "✓ Calculated TF-IDF for 211,691 genre-ngram pairs\n",
      "Calculating genre-level TF-IDF for bigrams with cat5 genres ...\n",
      "✓ Calculated TF-IDF for 2,920,224 genre-ngram pairs\n",
      "Calculating genre-level TF-IDF for trigrams with cat5 genres ...\n",
      "✓ Calculated TF-IDF for 7,928,576 genre-ngram pairs\n",
      "Counting artists per ngram (and saving dictionrary and loading precomputed if possible), takes a while...\n",
      "\n",
      "Counting artists per n-gram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108604/108604 [00:18<00:00, 5844.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Calculated artist diversity for 108,604 n-grams\n",
      "Counting artists per n-gram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2052265/2052265 [05:29<00:00, 6221.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Calculated artist diversity for 2,052,265 n-grams\n",
      "Counting artists per n-gram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6582416/6582416 [25:12<00:00, 4353.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Calculated artist diversity for 6,582,416 n-grams\n",
      "Filtering ngrams occurring in at least 50 artists...\n",
      "\n",
      "Ranking ngrams by genre and tfidf.\n",
      "\n",
      "Total unique ngrams selected: 148\n",
      "Total unique ngrams selected: 183\n",
      "Total unique ngrams selected: 248\n",
      "Total unique ngrams in final feature set: 579\n",
      "{\"i'm the\", 'of the earth', 'i wanna be', \"you ain't\", 'he', 'on me', 'your life', 'up in my', 'the way you', 'to the ground', 'into the', 'my eyes', 'you were', 'if you', 'from the', 'to see', 'my mind', 'so hard to', 'put', 'oh', 'see', 'the dead', 'i know you', 'so i can', \"i don't wanna\", 'for you', 'the sun', 'the time', 'out of', 'cause', 'yeah yeah yeah', 'it to the', 'as the', 'where', 'with my', 'if i', 'you know that', 'will', 'i know', 'know what i', 'the way that', 'through the', 'right', 'what', 'i am a', 'again', \"don't have to\", 'wanna', 'i know i', 'me to the', 'of a', 'feel the', \"i ain't\", 'left', 'from', 'you see', 'you and i', 'let', \"don't know\", 'this', 'that i', 'i had to', 'i see', 'me and my', 'and i got', 'you know you', 'take my hand', 'the dark', 'as', 'us', 'the same', 'for', 'oh oh oh', 'my', 'out the', 'on my mind', 'as long as', 'let me', \"i don't care\", 'too', 'i have', 'me and you', 'out in the', \"there's\", 'it', 'i see you', 'on the floor', 'what i', 'all i', 'if i could', 'been', \"don't give a\", 'uh uh uh', 'so', 'oh oh', 'in the air', 'all of the', 'the world', 'i will never', 'all the time', 'like the', 'with me', 'the land of', 'this is', 'could', \"i don't even\", 'but i', \"it's\", 'i can', 'out on the', 'in love with', 'back to the', 'we', 'come', \"i'll\", 'niggas', 'you know what', 'the name of', 'try to', \"i'm a\", 'off', 'you and me', 'to be', 'and', 'just', 'well', 'life', 'your eyes', 'the other side', 'to see you', 'the one', 'to me', 'every time i', 'you know i', \"i'm\", 'there is no', 'got', \"there's no\", 'of the dead', 'of my', 'you got', 'here we go', 'want', 'your', 'has', 'know you', 'i got the', 'you feel', \"if you don't\", 'the one who', 'in the sky', 'check it out', 'get', 'em', 'yeah yeah', 'to see the', 'i love you', 'be the one', \"and i'm\", 'what to do', 'no more', 'say', 'give', \"ain't no\", \"ain't\", 'a little bit', 'still', 'in the dark', 'i could', \"i ain't got\", 'i feel like', 'i will be', 'i need to', 'the weight of', 'an', 'the edge of', 'and the', \"i'm bout to\", 'i had', 'you know', 'this is a', 'when you', 'in the end', 'you i', 'of your', 'to the end', 'up', 'we are the', 'to get', 'i need a', \"know what i'm\", 'for the', 'gonna', 'go', 'out of my', 'know that i', 'my soul', 'then', 'you want', 'you will', 'in my mind', 'so i', 'i think', 'the world is', 'the things that', 'and you', 'back', 'in a world', 'there is a', 'i want you', 'through the night', 'of', 'i will', 'nothing', 'time', 'mind', 'need', 'fear', \"i don't\", 'know i', 'a nigga', 'eyes', 'money', 'when i', 'for you to', 'i need you', 'this shit', 'into the night', 'there is', 'me in the', 'down', 'me', 'we are', 'get it', 'of the night', 'in my life', \"you don't know\", 'there', 'nothing left to', \"but i don't\", 'to the', 'at the', 'nigga', 'the end of', 'with you i', 'i just', \"don't want to\", \"but i can't\", 'like a', 'the face of', 'the', \"don't\", 'be the', 'in a', 'a little', 'in this bitch', \"that's why i\", 'the ones who', 'away', 'love', 'i got', 'i try to', 'a', 'i can feel', 'time has come', \"don't know what\", 'i got a', \"and i ain't\", 'you can', 'the light of', 'end', \"that's\", 'her', 'my heart', \"i don't know\", 'my life', \"i don't give\", 'more', 'in the night', 'in the hood', 'know how to', 'every', 'in this', 'i am the', 'to you', 'me to', 'on the ground', 'in your', 'you', 'ooh ooh ooh', 'die', 'the fuck', 'how', 'pain', 'yeah i', 'all the things', 'know what', 'and you know', 'what you want', 'tell me what', 'these', 'to be the', 'for me', 'think', 'keep', 'for a', 'shit', 'i want', 'the sky', 'i get', 'with a', 'on the beat', \"can't\", 'for you and', 'out of the', 'of the', 'in the club', \"you know i'm\", 'in front of', 'i feel', 'death', 'if you want', 'when the', 'when', 'and i will', 'in my eyes', 'i feel the', 'but you', 'love you', 'on the block', 'you got a', 'all my', \"and i can't\", 'i am', 'it all', 'want to', 'you and', 'am', 'up the', 'up to the', 'that', 'man', 'away from the', 'in my heart', 'you want me', 'i used to', 'back in the', 'waiting for the', \"don't you know\", 'no one', 'in my', 'light', \"it's hard to\", 'yeah', 'and my', 'soul', 'know what to', 'up on the', 'here', 'i had a', 'in the name', 'i told you', 'now i know', 'and if you', 'to me i', 'at the end', \"i just can't\", 'this is my', 'do it', \"you're\", 'the truth', 'see the', 'from the sky', 'you to', 'in the morning', \"i don't want\", 'day', 'my heart is', 'by the', 'into', \"what i'm sayin\", 'i was a', 'this is the', 'in my head', 'it up', 'who', 'up and', 'you feel the', 'she', 'just a', 'on your', 'the light', 'i was born', 'up in the', 'by', 'me i', 'i just wanna', 'i', 'you know how', 'want to be', 'what you', 'i got it', 'in the house', 'cause i', 'it i', 'in', 'tell', \"and i don't\", 'world', 'about', 'me and', 'feel', 'the eyes of', 'you know the', \"it's a\", 'one', 'to say', 'make me feel', 'you make me', 'you in the', 'of death', \"i'm in the\", 'i was', 'are', 'on my', 'to', 'out', 'only', 'a world of', 'to do', \"there's nothing left\", 'on and on', 'inside of me', 'blood', 'if', 'through', \"i've\", 'that you', 'time to', 'the pain', 'i know what', 'are the', 'of life', \"can't you see\", 'be', 'you have to', 'i have to', 'got the', 'have', 'on the', 'i do', 'but i know', 'tell me', 'on my own', 'for me to', 'used to', 'bitch', 'you need to', \"you can't\", 'want me to', 'you got me', 'i see the', 'to be a', 'some', 'up in', 'the way', 'like', 'on a', 'it was', 'uh', 'know that', 'now i', 'that shit', 'in the', 'the only one', 'close my eyes', 'their', 'way', 'take', 'and all the', 'is', 'our', 'the end', 'the heart of', \"i'm not\", 'down to the', 'make', 'heart', 'have to', 'they', \"there's a\", 'by my side', 'fuck', 'you are', \"i'm on the\", 'around', 'lost in the', 'the blood of', 'and i know', 'as i', 'yeah yeah i', 'close your eyes', \"i don't need\", 'the night', 'not', 'for you i', 'the way i', 'end of the', 'all the', 'i got my', 'want you to', 'a part of', 'all', 'is a', \"you don't\", 'is the', 'never', 'it in the', 'when i was', 'with the', 'will be', 'dead', 'night', 'used to be', 'with you', \"it's time to\", 'with', 'fuck with me', \"i can't\", 'do', 'but', 'got a', 'i will not', 'make it', 'on', 'i wanna', \"i've been\", 'do you', 'in the back', 'me and i', 'give a fuck', 'you are the', 'the fuck you', 'inside', 'all my niggas', 'by your side', 'you tell me', 'i need', 'you love me', 'i love', 'at', 'what the fuck', 'i know that', 'the back of', 'of my life', 'you want to', 'and i', 'i want to', 'in this world', 'of the world', 'one by one', 'in your eyes', 'will be the', 'was', 'or', 'baby', 'no', 'the sound of', 'to die', 'can you hear', \"i know it's\", 'them', 'now', 'know', 'let you go', \"ain't got no\", 'i can see', 'can', 'a lot of'}\n",
      "Counting final ngrams in each track's lyrics, ~20s...\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 111938 entries, 0 to 111937\n",
      "Columns: 579 entries, a to your life\n",
      "dtypes: int64(579)\n",
      "memory usage: 494.5 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>a little</th>\n",
       "      <th>a little bit</th>\n",
       "      <th>a lot of</th>\n",
       "      <th>a nigga</th>\n",
       "      <th>a part of</th>\n",
       "      <th>a world of</th>\n",
       "      <th>about</th>\n",
       "      <th>again</th>\n",
       "      <th>ain't</th>\n",
       "      <th>...</th>\n",
       "      <th>you to</th>\n",
       "      <th>you want</th>\n",
       "      <th>you want me</th>\n",
       "      <th>you want to</th>\n",
       "      <th>you were</th>\n",
       "      <th>you will</th>\n",
       "      <th>you're</th>\n",
       "      <th>your</th>\n",
       "      <th>your eyes</th>\n",
       "      <th>your life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111933</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111934</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111935</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111936</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111937</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111938 rows × 579 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         a  a little  a little bit  a lot of  a nigga  a part of  a world of  \\\n",
       "0        0         0             0         0        0          0           0   \n",
       "1        0         0             0         0        0          0           0   \n",
       "2        2         0             0         0        0          0           0   \n",
       "3        0         0             0         0        0          0           0   \n",
       "4       15         0             0         0        0          0           0   \n",
       "...     ..       ...           ...       ...      ...        ...         ...   \n",
       "111933   1         0             0         0        0          0           0   \n",
       "111934   1         0             0         0        0          0           0   \n",
       "111935   0         0             0         0        0          0           0   \n",
       "111936   4         0             0         0        0          0           0   \n",
       "111937   9         0             0         0        0          0           0   \n",
       "\n",
       "        about  again  ain't  ...  you to  you want  you want me  you want to  \\\n",
       "0           0      1      0  ...       0         0            0            0   \n",
       "1           0      0      0  ...       0         0            0            0   \n",
       "2           0      0      0  ...       0         0            0            0   \n",
       "3           0      0      0  ...       0         0            0            0   \n",
       "4           0      0      0  ...       0         0            0            0   \n",
       "...       ...    ...    ...  ...     ...       ...          ...          ...   \n",
       "111933      0      0      1  ...       0         0            0            0   \n",
       "111934      0      0      0  ...       0         0            0            0   \n",
       "111935      1      1      0  ...       1         0            0            0   \n",
       "111936      0      1      0  ...       0         0            0            0   \n",
       "111937      0      0      0  ...       0         1            0            1   \n",
       "\n",
       "        you were  you will  you're  your  your eyes  your life  \n",
       "0              0         0       0     1          0          0  \n",
       "1              0         0       0     0          0          0  \n",
       "2              0         0       0     0          0          0  \n",
       "3              0         0       0     0          0          0  \n",
       "4              1         0       0     2          0          0  \n",
       "...          ...       ...     ...   ...        ...        ...  \n",
       "111933         0         0       0     1          0          0  \n",
       "111934         0         0       0     0          0          0  \n",
       "111935         0         0       0     0          0          0  \n",
       "111936         0         0       0     0          0          0  \n",
       "111937         0         1       2     3          0          0  \n",
       "\n",
       "[111938 rows x 579 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers.n_gram_features import build_ngram_features\n",
    "build_ngram_features(corpus=english, granularity=5, min_artists=50, top_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.n_gram_features import build_ngram_features\n",
    "build_ngram_features(corpus=english, granularity=12, min_artists=50, top_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c44c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.n_gram_features import build_ngram_features\n",
    "build_ngram_features(corpus=english, granularity=25, min_artists=50, top_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.n_gram_features import build_ngram_features\n",
    "build_ngram_features(corpus=english, granularity=32, min_artists=50, top_n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace67cc1",
   "metadata": {},
   "source": [
    "## Train SVM Model \n",
    "- train SVM with linear kernel on n-gram count features with parameter C=1\n",
    "- use one-vs-rest strategy for multi-class classification\n",
    "<!-- - use 5-fold cross validation to evaluate performance\n",
    "- report accuracy, precision, recall, F1-score per genre and overall -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62b6c647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 89012\n",
      "Test set size: 22926\n",
      "Number of unique artists in train: 5389\n",
      "Number of unique artists in test: 1348\n",
      "Artist overlap (should be 0): 0\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\models\\fell_spohrleder_svm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m features5 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/FS_G5_lyrics_n_gram_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# features12 = pd.read_csv(\"../data/FS_G12_lyrics_n_gram_features.csv\")\u001b[39;00m\n",
      "\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# features25 = pd.read_csv(\"../data/FS_G25_lyrics_n_gram_features.csv\")\u001b[39;00m\n",
      "\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# features32 = pd.read_csv(\"../data/FS_G32_lyrics_n_gram_features.csv\")\u001b[39;00m\n",
      "\u001b[1;32m---> 10\u001b[0m \u001b[43mperform_linear_SVC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_and_artists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgranularity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# perform_linear_SVM(features12, labels_and_artists, granularity=12)\u001b[39;00m\n",
      "\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# perform_linear_SVM(features25, labels_and_artists, granularity=25)\u001b[39;00m\n",
      "\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# perform_linear_SVM(features32, labels_and_artists, granularity=32)\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mN:\\Materialien\\Promotion\\LyricsGenreRecognition\\src\\helpers\\simple_linear_SVC.py:78\u001b[0m, in \u001b[0;36mperform_linear_SVC\u001b[1;34m(features, labels_and_artists, granularity)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lyrics\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n",
      "\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n",
      "\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n",
      "\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n",
      "\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n",
      "\u001b[0;32m    332\u001b[0m     )\n",
      "\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lyrics\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n",
      "\u001b[0;32m   3978\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n",
      "\u001b[0;32m   3980\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n",
      "\u001b[0;32m   3981\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n",
      "\u001b[0;32m   3982\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   3986\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n",
      "\u001b[0;32m   3987\u001b[0m )\n",
      "\u001b[1;32m-> 3989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   4000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   4001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   4002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   4003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   4004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   4005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   4006\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lyrics\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n",
      "\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n",
      "\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n",
      "\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n",
      "\u001b[0;32m   1013\u001b[0m )\n",
      "\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n",
      "\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lyrics\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n",
      "\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n",
      "\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n",
      "\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n",
      "\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n",
      "\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n",
      "\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n",
      "\u001b[0;32m    268\u001b[0m     )\n",
      "\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lyrics\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n",
      "\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n",
      "\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n",
      "\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n",
      "\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lyrics\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n",
      "\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n",
      "\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..\\models\\fell_spohrleder_svm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from helpers.simple_linear_SVC import perform_linear_SVC\n",
    "\n",
    "labels_and_artists = pd.read_csv(\"../data/poptrag_lyrics_genres_corpus_filtered_english.csv\")\n",
    "features5 = pd.read_csv(\"../data/FS_G5_lyrics_n_gram_features.csv\")\n",
    "# features12 = pd.read_csv(\"../data/FS_G12_lyrics_n_gram_features.csv\")\n",
    "# features25 = pd.read_csv(\"../data/FS_G25_lyrics_n_gram_features.csv\")\n",
    "# features32 = pd.read_csv(\"../data/FS_G32_lyrics_n_gram_features.csv\")\n",
    "\n",
    "perform_linear_SVC(features5, labels_and_artists, granularity=5)\n",
    "# perform_linear_SVM(features12, labels_and_artists, granularity=12)\n",
    "# perform_linear_SVM(features25, labels_and_artists, granularity=25)\n",
    "# perform_linear_SVM(features32, labels_and_artists, granularity=32)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
