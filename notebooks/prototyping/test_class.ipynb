{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc07b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 111938 entries, 0 to 111937\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Unnamed: 0                111938 non-null  int64  \n",
      " 1   track.s.id                111938 non-null  str    \n",
      " 2   track.s.title             111937 non-null  str    \n",
      " 3   track.s.firstartist.name  111938 non-null  str    \n",
      " 4   album.s.title             111938 non-null  str    \n",
      " 5   album.s.releaseyear       111938 non-null  int64  \n",
      " 6   track.s.popularity        111938 non-null  int64  \n",
      " 7   track.language            111938 non-null  str    \n",
      " 8   full_lyrics               111938 non-null  str    \n",
      " 9   cat5                      111938 non-null  str    \n",
      " 10  pmax5                     111938 non-null  float64\n",
      " 11  nmax5                     111938 non-null  float64\n",
      " 12  cat12                     111938 non-null  str    \n",
      " 13  pmax12                    111938 non-null  float64\n",
      " 14  nmax12                    111938 non-null  float64\n",
      " 15  cat25                     111938 non-null  str    \n",
      " 16  pmax25                    111938 non-null  float64\n",
      " 17  nmax25                    111938 non-null  float64\n",
      " 18  cat32                     111938 non-null  str    \n",
      " 19  pmax32                    111938 non-null  float64\n",
      " 20  nmax32                    111938 non-null  float64\n",
      " 21  lyrics_lemmatized         111938 non-null  str    \n",
      "dtypes: float64(8), int64(3), str(11)\n",
      "memory usage: 18.8 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "full = pd.read_csv(\"../../data/poptrag_lyrics_genres_corpus_filtered_english_lemmatized.csv\")\n",
    "full.info()\n",
    "\n",
    "# top 20 most common words in the lyrics\n",
    "# def print_most_common_words(corpus, lyrics_column, top_n=20):\n",
    "#     vectorizer = CountVectorizer(\n",
    "#                 ngram_range=(1, 1),\n",
    "#                 token_pattern=r\"\\b[\\w']+\\b\",\n",
    "#                 lowercase=True,\n",
    "#             )\n",
    "#     matrix = vectorizer.fit_transform(full[lyrics_column])\n",
    "#     sum_words = matrix.sum(axis=0)\n",
    "#     words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "#     words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "#     print(words_freq[:20])\n",
    "\n",
    "# print_most_common_words(full, \"full_lyrics\")\n",
    "# print(\"=\" * 60)\n",
    "# print_most_common_words(full, \"lyrics_lemmatized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7501b606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted unigrams:\n",
      "  - Unique: 9,057\n",
      "  - Shape: (893, 9057)\n",
      "  - Examples: ['cuffs', 'asphyxiated', 'lies', 'inspire', 'hersheys']\n",
      "✓ Extracted bigrams:\n",
      "  - Unique: 55,891\n",
      "  - Shape: (893, 55891)\n",
      "  - Examples: ['stay or', 'bueno chinga', 'aimlessly but', 'town yeah', 'goodbye the']\n",
      "✓ Extracted trigrams:\n",
      "  - Unique: 95,312\n",
      "  - Shape: (893, 95312)\n",
      "  - Examples: ['wait in silence', 'challenged all across', 'all made the', \"i'm off st\", 'hit oh by']\n",
      "Calculating genre-level TF-IDF for unigrams with genre ...\n",
      "✓ Calculated TF-IDF for 19,739 genre-ngram pairs\n",
      "Calculating genre-level TF-IDF for bigrams with genre ...\n",
      "✓ Calculated TF-IDF for 74,810 genre-ngram pairs\n",
      "Calculating genre-level TF-IDF for trigrams with genre ...\n",
      "✓ Calculated TF-IDF for 101,923 genre-ngram pairs\n",
      "Counting artists per n-gram...\n",
      "  10% complete\n",
      "  20% complete\n",
      "  30% complete\n",
      "  40% complete\n",
      "  50% complete\n",
      "  60% complete\n",
      "  70% complete\n",
      "  80% complete\n",
      "  90% complete\n",
      "✓ Calculated artist diversity for 9,057 n-grams\n",
      "Counting artists per n-gram...\n",
      "  10% complete\n",
      "  20% complete\n",
      "  30% complete\n",
      "  40% complete\n",
      "  50% complete\n",
      "  60% complete\n",
      "  70% complete\n",
      "  80% complete\n",
      "  90% complete\n",
      "✓ Calculated artist diversity for 55,891 n-grams\n",
      "Counting artists per n-gram...\n",
      "  10% complete\n",
      "  20% complete\n",
      "  30% complete\n",
      "  40% complete\n",
      "  50% complete\n",
      "  60% complete\n",
      "  70% complete\n",
      "  80% complete\n",
      "  90% complete\n",
      "✓ Calculated artist diversity for 95,312 n-grams\n",
      "Total unique n-grams: 580\n",
      "LyricsClassificationExperiment with 11 genres\n",
      "=============================================\n",
      "Train size: 893 samples\n",
      "Test size: 226 samples\n",
      "# of features: 580\n",
      "Feature type: Fell-Spohrleder (2014) N-grams (top 100, min. 20 artists)\n",
      "Model not yet trained.\n",
      "=============================================\n",
      "Output directory: cat5_mock_experiment_fs\n",
      "\n",
      "<class 'pandas.DataFrame'>\n",
      "Training pipeline with fixed parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model parameters:\n",
      "  C: 1.000\n",
      "  l1_ratio: 0.500\n",
      "  target_ratio: 3.000\n",
      "============================================================\n",
      "F1 macro: 0.169\n",
      "Precision macro: 0.169\n",
      "Recall macro: 0.169\n",
      "Cohen's kappa: 0.130\n",
      "============================================================\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "alternative rock       0.17      0.08      0.11        13\n",
      "      electronic       0.05      0.05      0.05        19\n",
      "       hard rock       0.00      0.00      0.00         7\n",
      "     heavy metal       0.14      0.22      0.17         9\n",
      "         hip hop       0.43      0.40      0.41        15\n",
      "      indie rock       0.00      0.00      0.00         5\n",
      "            jazz       0.00      0.00      0.00         3\n",
      "           metal       0.33      0.42      0.37        24\n",
      "             pop       0.35      0.42      0.39        52\n",
      "        pop rock       0.00      0.00      0.00         2\n",
      "            rock       0.39      0.34      0.36        77\n",
      "\n",
      "        accuracy                           0.30       226\n",
      "       macro avg       0.17      0.18      0.17       226\n",
      "    weighted avg       0.30      0.30      0.30       226\n",
      "\n",
      "Top 10 coefficients for genre: ALTERNATIVE ROCK\n",
      "you go (0.465)\n",
      "for me (0.429)\n",
      "fall (0.391)\n",
      "back to (0.381)\n",
      "she (0.368)\n",
      "every (0.365)\n",
      "need to (0.355)\n",
      "not (-0.348)\n",
      "and then (0.330)\n",
      "me i (0.324)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: ELECTRONIC\n",
      "my soul (0.543)\n",
      "as (-0.503)\n",
      "down (-0.474)\n",
      "hear (-0.461)\n",
      "break (0.450)\n",
      "keep (0.417)\n",
      "i can't (-0.394)\n",
      "baby i (0.393)\n",
      "how to (0.371)\n",
      "waiting for (0.365)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: HARD ROCK\n",
      "ooh (0.511)\n",
      "i ain't (0.454)\n",
      "world (0.440)\n",
      "street (0.425)\n",
      "be a (0.366)\n",
      "not (0.351)\n",
      "you have (0.350)\n",
      "just a (0.350)\n",
      "girl (0.342)\n",
      "gone (0.332)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: HEAVY METAL\n",
      "heaven (0.605)\n",
      "this (-0.515)\n",
      "pain (0.514)\n",
      "forever (0.500)\n",
      "got (-0.414)\n",
      "always (0.413)\n",
      "for your (0.411)\n",
      "you'll (0.408)\n",
      "the wind (0.367)\n",
      "their (0.365)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: HIP HOP\n",
      "em (1.096)\n",
      "die (0.574)\n",
      "shit (0.539)\n",
      "fuck (0.430)\n",
      "ass (0.424)\n",
      "put (0.356)\n",
      "rain (0.353)\n",
      "big (0.349)\n",
      "hell (0.347)\n",
      "yeah (0.327)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: INDIE ROCK\n",
      "i said (0.524)\n",
      "run (0.400)\n",
      "with a (0.375)\n",
      "words (0.370)\n",
      "i see (0.351)\n",
      "everything (0.350)\n",
      "and i (0.348)\n",
      "hard (0.348)\n",
      "old (0.339)\n",
      "i want to (0.325)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: JAZZ\n",
      "phone (0.520)\n",
      "won't (0.516)\n",
      "he (0.404)\n",
      "love is (0.346)\n",
      "i hear (0.338)\n",
      "you i (0.310)\n",
      "day (0.288)\n",
      "and it's (0.284)\n",
      "of a (0.277)\n",
      "those (0.258)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: METAL\n",
      "lies (0.582)\n",
      "so (-0.563)\n",
      "and the (-0.529)\n",
      "be the (0.511)\n",
      "of (0.506)\n",
      "these (0.498)\n",
      "like (-0.470)\n",
      "am i (0.461)\n",
      "come to (0.424)\n",
      "got (-0.420)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: POP\n",
      "are (0.650)\n",
      "go (0.601)\n",
      "to lose (-0.594)\n",
      "i feel (0.559)\n",
      "gone (0.546)\n",
      "from the (-0.537)\n",
      "the wind (-0.517)\n",
      "shit (-0.500)\n",
      "these (-0.491)\n",
      "you are (0.487)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: POP ROCK\n",
      "hear (0.390)\n",
      "she's (0.344)\n",
      "the past (0.293)\n",
      "me i (0.273)\n",
      "me i'm (0.266)\n",
      "looking (0.263)\n",
      "time (0.235)\n",
      "like you (0.228)\n",
      "me and (0.227)\n",
      "baby (0.220)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: ROCK\n",
      "uh (-0.583)\n",
      "all your (0.579)\n",
      "me and (-0.534)\n",
      "ass (-0.528)\n",
      "don't know (-0.528)\n",
      "as the (0.516)\n",
      "go (0.483)\n",
      "been (0.466)\n",
      "the only (0.466)\n",
      "shit (-0.463)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from helpers.LyricsClassficationExperiment import LyricsClassificationExperiment\n",
    "\n",
    "exp_fs = LyricsClassificationExperiment(\n",
    "    corpus=full, \n",
    "    genrecol=\"cat12\",\n",
    "    lyricscol=\"full_lyrics\", \n",
    "    artistcol=\"track.s.firstartist.name\", \n",
    "    output_dir=\"cat5_mock_experiment_fs\",\n",
    "    test_size=0.2,\n",
    "    random_state=42, \n",
    "    subsample_debug=0.01,\n",
    ")\n",
    "exp_fs.compute_fs_ngram_features(min_artists=20, top_n=100)\n",
    "fs_features = exp_fs.X_train.keys()\n",
    "print(exp_fs)\n",
    "print(type(exp_fs.X_train))\n",
    "exp_fs.train_fixed_parametrer_logistic_regression()\n",
    "exp_fs.show_model_evaluation()\n",
    "exp_fs.show_top_coefficients_per_genre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982b4b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted unigrams:\n",
      "  - Unique: 7,344\n",
      "  - Shape: (893, 7344)\n",
      "  - Examples: ['review', \"c'mon\", 'almost', 'stole', 'fail']\n",
      "✓ Extracted bigrams:\n",
      "  - Unique: 38,109\n",
      "  - Shape: (893, 38109)\n",
      "  - Examples: ['cursed beauty', 'alone most', 'look around', \"it's one\", 'i sure']\n",
      "✓ Extracted trigrams:\n",
      "  - Unique: 59,049\n",
      "  - Shape: (893, 59049)\n",
      "  - Examples: ['spain to tijuana', 'billy wake up', 'a wild flame', 'those nice thing', 'guess you know']\n",
      "Boundary stripping bigrams: kept 34,556 / 38,109 (dropped 3,553)\n",
      "Boundary stripping trigrams: kept 51,282 / 59,049 (dropped 7,767)\n",
      "Counting artists per n-gram...\n",
      "  10% complete\n",
      "  20% complete\n",
      "  30% complete\n",
      "  40% complete\n",
      "  50% complete\n",
      "  60% complete\n",
      "  70% complete\n",
      "  80% complete\n",
      "  90% complete\n",
      "✓ Calculated artist diversity for 7,344 n-grams\n",
      "Counting artists per n-gram...\n",
      "  10% complete\n",
      "  20% complete\n",
      "  30% complete\n",
      "  40% complete\n",
      "  50% complete\n",
      "  60% complete\n",
      "  70% complete\n",
      "  80% complete\n",
      "  90% complete\n",
      "✓ Calculated artist diversity for 34,556 n-grams\n",
      "Counting artists per n-gram...\n",
      "  10% complete\n",
      "  20% complete\n",
      "  30% complete\n",
      "  40% complete\n",
      "  50% complete\n",
      "  60% complete\n",
      "  70% complete\n",
      "  80% complete\n",
      "  90% complete\n",
      "✓ Calculated artist diversity for 51,282 n-grams\n",
      "Calculating genre-level TF-IDF for unigrams with genre ...\n",
      "✓ Calculated TF-IDF for 15,572 genre-ngram pairs\n",
      "Calculating genre-level TF-IDF for bigrams with genre ...\n",
      "✓ Calculated TF-IDF for 45,197 genre-ngram pairs\n",
      "Calculating genre-level TF-IDF for trigrams with genre ...\n",
      "✓ Calculated TF-IDF for 55,505 genre-ngram pairs\n",
      "Total unique n-grams: 452\n",
      "LyricsClassificationExperiment with 11 genres\n",
      "=============================================\n",
      "Train size: 893 samples\n",
      "Test size: 226 samples\n",
      "# of features: 452\n",
      "Feature type: Informed N-grams (top 100, min. 20 artists)\n",
      "Model not yet trained.\n",
      "=============================================\n",
      "Output directory: cat5_mock_experiment_informed\n",
      "\n",
      "<class 'pandas.DataFrame'>\n",
      "Training pipeline with fixed parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model parameters:\n",
      "  C: 1.000\n",
      "  l1_ratio: 0.500\n",
      "  target_ratio: 3.000\n",
      "============================================================\n",
      "F1 macro: 0.196\n",
      "Precision macro: 0.202\n",
      "Recall macro: 0.202\n",
      "Cohen's kappa: 0.184\n",
      "============================================================\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "alternative rock       0.00      0.00      0.00        13\n",
      "      electronic       0.15      0.26      0.19        19\n",
      "       hard rock       0.20      0.14      0.17         7\n",
      "     heavy metal       0.12      0.11      0.12         9\n",
      "         hip hop       0.54      0.47      0.50        15\n",
      "      indie rock       0.00      0.00      0.00         5\n",
      "            jazz       0.00      0.00      0.00         3\n",
      "           metal       0.29      0.29      0.29        24\n",
      "             pop       0.45      0.48      0.46        52\n",
      "        pop rock       0.00      0.00      0.00         2\n",
      "            rock       0.47      0.39      0.43        77\n",
      "\n",
      "        accuracy                           0.34       226\n",
      "       macro avg       0.20      0.20      0.20       226\n",
      "    weighted avg       0.35      0.34      0.34       226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from helpers.LyricsClassficationExperiment import LyricsClassificationExperiment\n",
    "\n",
    "exp_informed = LyricsClassificationExperiment(\n",
    "    corpus=full,\n",
    "    genrecol=\"cat12\",\n",
    "    lyricscol=\"lyrics_lemmatized\",\n",
    "    artistcol=\"track.s.firstartist.name\",\n",
    "    output_dir=\"cat5_mock_experiment_informed\",\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    subsample_debug=0.01,\n",
    "    # subsample_debug=0.1,\n",
    ")\n",
    "exp_informed.compute_informed_ngram_features(min_artists=20, top_n=100)\n",
    "fs_features = exp_informed.X_train.keys()\n",
    "print(exp_informed)\n",
    "print(type(exp_informed.X_train))\n",
    "exp_informed.train_fixed_parametrer_logistic_regression()\n",
    "exp_informed.show_model_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9404b569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMED\n",
      "============================================================\n",
      "Top 20 coefficients for genre: ALTERNATIVE ROCK\n",
      "oh (0.714)\n",
      "around (-0.701)\n",
      "say (-0.649)\n",
      "heart (0.612)\n",
      "man (0.576)\n",
      "somebody (0.569)\n",
      "see (-0.557)\n",
      "miss (0.552)\n",
      "come (-0.543)\n",
      "like (0.539)\n",
      "let (0.526)\n",
      "one (0.509)\n",
      "old (0.501)\n",
      "every (0.465)\n",
      "star (0.453)\n",
      "lose (0.451)\n",
      "get (0.432)\n",
      "eye (-0.406)\n",
      "fall (0.402)\n",
      "wonder (0.373)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: ELECTRONIC\n",
      "end (-0.892)\n",
      "home (-0.716)\n",
      "meet (-0.692)\n",
      "everything (-0.692)\n",
      "far (-0.641)\n",
      "blind (-0.637)\n",
      "sound (-0.625)\n",
      "heart (-0.616)\n",
      "flame (0.590)\n",
      "side (-0.588)\n",
      "darkness (0.576)\n",
      "move (-0.568)\n",
      "always (-0.566)\n",
      "even (-0.557)\n",
      "line (-0.525)\n",
      "goin (-0.522)\n",
      "door (0.502)\n",
      "alive (0.501)\n",
      "break (0.501)\n",
      "talk (-0.493)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: HARD ROCK\n",
      "talk (0.720)\n",
      "save (0.673)\n",
      "street (0.663)\n",
      "people (0.560)\n",
      "wall (0.557)\n",
      "tonight (0.508)\n",
      "leave (0.498)\n",
      "today (0.445)\n",
      "way (0.435)\n",
      "last (0.422)\n",
      "bleed (0.419)\n",
      "meet (0.411)\n",
      "pass (0.383)\n",
      "home (0.369)\n",
      "stick (0.337)\n",
      "wild (0.334)\n",
      "head (0.323)\n",
      "line (0.318)\n",
      "behind (-0.317)\n",
      "reason (0.316)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: HEAVY METAL\n",
      "get (-0.869)\n",
      "cry (0.708)\n",
      "wait (0.593)\n",
      "soul (0.561)\n",
      "flame (0.548)\n",
      "die (0.537)\n",
      "meet (0.537)\n",
      "sound (-0.526)\n",
      "land (0.514)\n",
      "thing (-0.497)\n",
      "hurt (-0.491)\n",
      "play (0.487)\n",
      "forget (-0.486)\n",
      "carry (0.483)\n",
      "tell (0.444)\n",
      "fear (0.419)\n",
      "house (0.388)\n",
      "death (0.372)\n",
      "every (-0.371)\n",
      "bear (0.364)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: HIP HOP\n",
      "nigga (1.243)\n",
      "em (1.055)\n",
      "bitch (0.813)\n",
      "like (0.621)\n",
      "shit (0.580)\n",
      "drop (0.538)\n",
      "yeah (0.532)\n",
      "bring (0.518)\n",
      "red (0.491)\n",
      "war (0.490)\n",
      "really (0.482)\n",
      "put (0.464)\n",
      "uh (0.458)\n",
      "die (0.452)\n",
      "hell (0.450)\n",
      "burn (-0.423)\n",
      "fuck (0.420)\n",
      "turn (-0.410)\n",
      "play (0.392)\n",
      "dark (-0.388)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: INDIE ROCK\n",
      "everything (0.723)\n",
      "bad (0.660)\n",
      "say (0.647)\n",
      "never (0.478)\n",
      "water (0.477)\n",
      "bed (0.453)\n",
      "way (0.431)\n",
      "sound (0.422)\n",
      "hard (0.409)\n",
      "get (-0.408)\n",
      "side (0.399)\n",
      "work (0.388)\n",
      "room (0.388)\n",
      "forever (0.386)\n",
      "throw (0.384)\n",
      "broken (0.378)\n",
      "give (0.372)\n",
      "old (0.371)\n",
      "hell (-0.368)\n",
      "last (0.362)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: JAZZ\n",
      "game (0.529)\n",
      "want (0.527)\n",
      "heart (0.525)\n",
      "hear (0.522)\n",
      "blow (0.475)\n",
      "line (0.469)\n",
      "write (0.466)\n",
      "bed (0.458)\n",
      "phone (0.457)\n",
      "life (-0.430)\n",
      "u (0.429)\n",
      "regret (0.411)\n",
      "far (0.400)\n",
      "walk (0.397)\n",
      "touch (0.388)\n",
      "stay (0.371)\n",
      "forget (0.340)\n",
      "stop (0.330)\n",
      "always (-0.315)\n",
      "sun (0.309)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: METAL\n",
      "dead (0.959)\n",
      "go (-0.885)\n",
      "need (-0.774)\n",
      "run (-0.731)\n",
      "tell (-0.654)\n",
      "fuck (0.588)\n",
      "like (-0.583)\n",
      "voice (0.565)\n",
      "sweet (-0.525)\n",
      "get (-0.517)\n",
      "ain't (-0.514)\n",
      "step (0.510)\n",
      "play (-0.506)\n",
      "nothing (0.504)\n",
      "stop (-0.498)\n",
      "far (0.483)\n",
      "shit (0.480)\n",
      "see (-0.458)\n",
      "mind (0.455)\n",
      "please (-0.452)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: POP\n",
      "red (-0.996)\n",
      "shit (-0.914)\n",
      "yes (0.855)\n",
      "shake (0.853)\n",
      "ah (-0.782)\n",
      "really (0.771)\n",
      "goodbye (-0.743)\n",
      "think (-0.717)\n",
      "em (0.677)\n",
      "sweet (0.670)\n",
      "who's (0.644)\n",
      "love (0.642)\n",
      "feel (0.598)\n",
      "yeah (0.595)\n",
      "even (0.583)\n",
      "mind (0.579)\n",
      "street (0.568)\n",
      "always (0.559)\n",
      "work (-0.534)\n",
      "phone (-0.528)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: POP ROCK\n",
      "gonna (0.610)\n",
      "gotta (0.559)\n",
      "miss (0.558)\n",
      "baby (0.548)\n",
      "ever (0.519)\n",
      "think (0.518)\n",
      "meet (0.462)\n",
      "child (0.429)\n",
      "hear (0.394)\n",
      "look (0.369)\n",
      "sick (0.352)\n",
      "time (0.350)\n",
      "window (0.327)\n",
      "forever (0.317)\n",
      "feeling (0.296)\n",
      "burn (0.291)\n",
      "boy (0.257)\n",
      "guess (0.257)\n",
      "find (0.238)\n",
      "walk (0.236)\n",
      "\n",
      "\n",
      "Top 20 coefficients for genre: ROCK\n",
      "uh (-0.857)\n",
      "stop (-0.771)\n",
      "close (-0.764)\n",
      "much (-0.753)\n",
      "today (0.719)\n",
      "shit (-0.665)\n",
      "pay (0.621)\n",
      "become (-0.605)\n",
      "well (0.573)\n",
      "year (0.558)\n",
      "ground (-0.534)\n",
      "cry (0.529)\n",
      "write (-0.521)\n",
      "please (-0.512)\n",
      "body (0.499)\n",
      "come (-0.476)\n",
      "give (0.466)\n",
      "lay (-0.461)\n",
      "mind (0.460)\n",
      "sky (-0.458)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(\"FS\\n\" + \"=\" * 60)\n",
    "# exp_fs.show_top_coefficients_per_genre()\n",
    "print(\"INFORMED\\n\" + \"=\" * 60)\n",
    "exp_informed.show_top_coefficients_per_genre(top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e75b25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "ah\n",
      "ain't\n",
      "alive\n",
      "alone\n",
      "along\n",
      "always\n",
      "always be\n",
      "another\n",
      "apart\n",
      "around\n",
      "ask\n",
      "away\n",
      "babe\n",
      "baby\n",
      "back\n",
      "back to\n",
      "bad\n",
      "be go\n",
      "be right\n",
      "bear\n",
      "become\n",
      "bed\n",
      "begin\n",
      "behind\n",
      "believe\n",
      "big\n",
      "bitch\n",
      "black\n",
      "blame\n",
      "bleed\n",
      "blind\n",
      "blood\n",
      "blow\n",
      "blue\n",
      "body\n",
      "bout\n",
      "boy\n",
      "break\n",
      "breathe\n",
      "bring\n",
      "broken\n",
      "brother\n",
      "burn\n",
      "call\n",
      "call me\n",
      "can see\n",
      "car\n",
      "care\n",
      "carry\n",
      "catch\n",
      "cause\n",
      "cause i\n",
      "cause you\n",
      "chance\n",
      "change\n",
      "child\n",
      "close\n",
      "cold\n",
      "come\n",
      "come on\n",
      "come to\n",
      "control\n",
      "cry\n",
      "dark\n",
      "darkness\n",
      "day\n",
      "dead\n",
      "death\n",
      "deep\n",
      "die\n",
      "don't know\n",
      "don't need\n",
      "don't wanna\n",
      "don't want\n",
      "door\n",
      "dream\n",
      "drink\n",
      "drop\n",
      "easy\n",
      "em\n",
      "end\n",
      "enough\n",
      "even\n",
      "ever\n",
      "every\n",
      "every day\n",
      "everything\n",
      "eye\n",
      "face\n",
      "faith\n",
      "fall\n",
      "far\n",
      "fear\n",
      "feel\n",
      "feel like\n",
      "feeling\n",
      "fight\n",
      "find\n",
      "fire\n",
      "flame\n",
      "fly\n",
      "forever\n",
      "forget\n",
      "free\n",
      "friend\n",
      "fuck\n",
      "full\n",
      "full of\n",
      "fun\n",
      "future\n",
      "game\n",
      "get\n",
      "get it\n",
      "get me\n",
      "get my\n",
      "get to\n",
      "girl\n",
      "give\n",
      "give me\n",
      "give you\n",
      "go\n",
      "go on\n",
      "go out\n",
      "go to\n",
      "god\n",
      "goin\n",
      "gonna\n",
      "good\n",
      "goodbye\n",
      "gotta\n",
      "great\n",
      "ground\n",
      "grow\n",
      "guess\n",
      "hand\n",
      "hard\n",
      "hard to\n",
      "hate\n",
      "head\n",
      "hear\n",
      "heart\n",
      "heart be\n",
      "heaven\n",
      "hell\n",
      "hey\n",
      "hide\n",
      "high\n",
      "hit\n",
      "hold\n",
      "home\n",
      "hope\n",
      "hot\n",
      "house\n",
      "hurt\n",
      "i ain't\n",
      "i don't know\n",
      "i feel\n",
      "i get\n",
      "i go\n",
      "i hear\n",
      "i know\n",
      "i love\n",
      "i need\n",
      "i never\n",
      "i say\n",
      "i see\n",
      "i take\n",
      "i tell\n",
      "i think\n",
      "i try\n",
      "i wanna\n",
      "i want\n",
      "i want to\n",
      "i would\n",
      "i'm gonna\n",
      "i've get\n",
      "in love\n",
      "in the dark\n",
      "inside\n",
      "it seem\n",
      "just like\n",
      "keep\n",
      "keep on\n",
      "kid\n",
      "kill\n",
      "kind\n",
      "kind of\n",
      "kiss\n",
      "know\n",
      "know how\n",
      "know i\n",
      "know it's\n",
      "know that\n",
      "know what\n",
      "know you\n",
      "lady\n",
      "land\n",
      "last\n",
      "lay\n",
      "lead\n",
      "leave\n",
      "leave me\n",
      "let\n",
      "let it\n",
      "let me\n",
      "let you\n",
      "let's\n",
      "lie\n",
      "life\n",
      "life be\n",
      "light\n",
      "like\n",
      "like i\n",
      "like to\n",
      "like you\n",
      "line\n",
      "little\n",
      "live\n",
      "lonely\n",
      "long\n",
      "look\n",
      "look at\n",
      "lose\n",
      "love\n",
      "love be\n",
      "love me\n",
      "love you\n",
      "make\n",
      "make it\n",
      "make me\n",
      "make you\n",
      "man\n",
      "maybe\n",
      "meet\n",
      "mind\n",
      "mine\n",
      "miss\n",
      "money\n",
      "move\n",
      "much\n",
      "my eye\n",
      "my friend\n",
      "my hand\n",
      "my head\n",
      "my heart\n",
      "my life\n",
      "my love\n",
      "my mind\n",
      "my soul\n",
      "name\n",
      "need\n",
      "need to\n",
      "need you\n",
      "never\n",
      "never be\n",
      "new\n",
      "nigga\n",
      "night\n",
      "no one\n",
      "nothing\n",
      "of love\n",
      "oh\n",
      "oh i\n",
      "oh oh\n",
      "old\n",
      "one\n",
      "only one\n",
      "ooh\n",
      "open\n",
      "pain\n",
      "pass\n",
      "past\n",
      "pay\n",
      "people\n",
      "phone\n",
      "picture\n",
      "place\n",
      "play\n",
      "please\n",
      "power\n",
      "pretty\n",
      "promise\n",
      "put\n",
      "rain\n",
      "real\n",
      "really\n",
      "reason\n",
      "red\n",
      "regret\n",
      "remember\n",
      "ride\n",
      "right\n",
      "rise\n",
      "rock\n",
      "roll\n",
      "room\n",
      "run\n",
      "save\n",
      "say\n",
      "say i\n",
      "say that\n",
      "say you\n",
      "scream\n",
      "see\n",
      "see you\n",
      "seem\n",
      "set\n",
      "shadow\n",
      "shake\n",
      "she say\n",
      "shit\n",
      "show\n",
      "sick\n",
      "side\n",
      "silence\n",
      "sit\n",
      "skin\n",
      "sky\n",
      "smile\n",
      "so much\n",
      "somebody\n",
      "someone\n",
      "something\n",
      "song\n",
      "sorry\n",
      "soul\n",
      "sound\n",
      "stand\n",
      "star\n",
      "start\n",
      "start to\n",
      "stay\n",
      "step\n",
      "stick\n",
      "still\n",
      "stop\n",
      "stranger\n",
      "street\n",
      "sun\n",
      "sweet\n",
      "take\n",
      "take it\n",
      "take me\n",
      "take my\n",
      "take you\n",
      "talk\n",
      "tear\n",
      "tell\n",
      "tell me\n",
      "tell you\n",
      "they say\n",
      "thing\n",
      "thing that\n",
      "think\n",
      "think that\n",
      "this time\n",
      "thought\n",
      "throw\n",
      "til\n",
      "time\n",
      "time to\n",
      "to die\n",
      "to find\n",
      "to get\n",
      "to go\n",
      "to know\n",
      "to live\n",
      "to lose\n",
      "to make\n",
      "to say\n",
      "to see\n",
      "to take\n",
      "to tell\n",
      "today\n",
      "together\n",
      "tonight\n",
      "touch\n",
      "town\n",
      "true\n",
      "truth\n",
      "try\n",
      "try to\n",
      "turn\n",
      "turn to\n",
      "two\n",
      "u\n",
      "uh\n",
      "use\n",
      "use to\n",
      "voice\n",
      "wait\n",
      "wait for\n",
      "wake up\n",
      "walk\n",
      "wall\n",
      "wanna\n",
      "want\n",
      "want to\n",
      "war\n",
      "warm\n",
      "waste\n",
      "watch\n",
      "water\n",
      "way\n",
      "way to\n",
      "well\n",
      "well i\n",
      "what's\n",
      "white\n",
      "who's\n",
      "wild\n",
      "wind\n",
      "window\n",
      "woman\n",
      "wonder\n",
      "word\n",
      "work\n",
      "world\n",
      "would\n",
      "write\n",
      "wrong\n",
      "ya\n",
      "yeah\n",
      "yeah yeah\n",
      "year\n",
      "yes\n",
      "you feel\n",
      "you get\n",
      "you go\n",
      "you know\n",
      "you leave\n",
      "you like\n",
      "you make\n",
      "you need\n",
      "you never\n",
      "you say\n",
      "you see\n",
      "you take\n",
      "you think\n",
      "you wanna\n",
      "you want\n",
      "you've get\n",
      "young\n",
      "your eye\n",
      "your face\n",
      "your hand\n",
      "your heart\n",
      "your life\n",
      "your love\n",
      "your mind\n",
      "your name\n"
     ]
    }
   ],
   "source": [
    "for feautre in exp_informed.X_train.columns:\n",
    "    print(feautre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0cb6093",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feautre \u001b[38;5;129;01min\u001b[39;00m \u001b[43mexp_fs\u001b[49m\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(feautre)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exp_fs' is not defined"
     ]
    }
   ],
   "source": [
    "for feautre in exp_fs.X_train.columns:\n",
    "    print(feautre)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
