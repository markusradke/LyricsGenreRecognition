{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc07b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 111938 entries, 0 to 111937\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Unnamed: 0                111938 non-null  int64  \n",
      " 1   track.s.id                111938 non-null  str    \n",
      " 2   track.s.title             111937 non-null  str    \n",
      " 3   track.s.firstartist.name  111938 non-null  str    \n",
      " 4   album.s.title             111938 non-null  str    \n",
      " 5   album.s.releaseyear       111938 non-null  int64  \n",
      " 6   track.s.popularity        111938 non-null  int64  \n",
      " 7   track.language            111938 non-null  str    \n",
      " 8   full_lyrics               111938 non-null  str    \n",
      " 9   cat5                      111938 non-null  str    \n",
      " 10  pmax5                     111938 non-null  float64\n",
      " 11  nmax5                     111938 non-null  float64\n",
      " 12  cat12                     111938 non-null  str    \n",
      " 13  pmax12                    111938 non-null  float64\n",
      " 14  nmax12                    111938 non-null  float64\n",
      " 15  cat25                     111938 non-null  str    \n",
      " 16  pmax25                    111938 non-null  float64\n",
      " 17  nmax25                    111938 non-null  float64\n",
      " 18  cat32                     111938 non-null  str    \n",
      " 19  pmax32                    111938 non-null  float64\n",
      " 20  nmax32                    111938 non-null  float64\n",
      " 21  lyrics_lemmatized         111938 non-null  str    \n",
      "dtypes: float64(8), int64(3), str(11)\n",
      "memory usage: 18.8 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "full = pd.read_csv(\"../../data/poptrag_lyrics_genres_corpus_filtered_english_lemmatized.csv\")\n",
    "full.info()\n",
    "\n",
    "# top 20 most common words in the lyrics\n",
    "# def print_most_common_words(corpus, lyrics_column, top_n=20):\n",
    "#     vectorizer = CountVectorizer(\n",
    "#                 ngram_range=(1, 1),\n",
    "#                 token_pattern=r\"\\b[\\w']+\\b\",\n",
    "#                 lowercase=True,\n",
    "#             )\n",
    "#     matrix = vectorizer.fit_transform(full[lyrics_column])\n",
    "#     sum_words = matrix.sum(axis=0)\n",
    "#     words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "#     words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "#     print(words_freq[:20])\n",
    "\n",
    "# print_most_common_words(full, \"full_lyrics\")\n",
    "# print(\"=\" * 60)\n",
    "# print_most_common_words(full, \"lyrics_lemmatized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7501b606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted unigrams:\n",
      "  - Unique: 21,575\n",
      "  - Shape: (4458, 21575)\n",
      "  - Examples: ['wives', 'colt', 'antibiotics', 'huckleberry', 'grams']\n",
      "Extracted bigrams:\n",
      "  - Unique: 194,350\n",
      "  - Shape: (4458, 194350)\n",
      "  - Examples: ['to department', \"castaway i'll\", 'all wanting', 'her lively', 'going unconditional']\n",
      "Extracted trigrams:\n",
      "  - Unique: 410,566\n",
      "  - Shape: (4458, 410566)\n",
      "  - Examples: [\"things you've always\", 'calling save me', 'air to soothe', 'working on the', 'hotter in your']\n",
      "Calculating genre-level TF-IDF for unigrams with genre ...\n",
      "Calculated TF-IDF for 51,624 genre-ngram pairs\n",
      "Calculating genre-level TF-IDF for bigrams with genre ...\n",
      "Calculated TF-IDF for 285,738 genre-ngram pairs\n",
      "Calculating genre-level TF-IDF for trigrams with genre ...\n",
      "Calculated TF-IDF for 467,138 genre-ngram pairs\n",
      "Counting artists per n-gram...\n",
      "  10% complete\n",
      "  20% complete\n",
      "  30% complete\n",
      "  40% complete\n",
      "  50% complete\n",
      "  60% complete\n",
      "  70% complete\n",
      "  80% complete\n",
      "  90% complete\n",
      "Calculated artist diversity for 21,575 n-grams\n",
      "Counting artists per n-gram...\n",
      "  10% complete\n",
      "  20% complete\n",
      "  30% complete\n",
      "  40% complete\n",
      "  50% complete\n",
      "  60% complete\n",
      "  70% complete\n",
      "  80% complete\n",
      "  90% complete\n",
      "Calculated artist diversity for 194,350 n-grams\n",
      "Counting artists per n-gram...\n",
      "  10% complete\n",
      "  20% complete\n",
      "  30% complete\n",
      "  40% complete\n",
      "  50% complete\n",
      "  60% complete\n",
      "  70% complete\n",
      "  80% complete\n",
      "  90% complete\n",
      "Calculated artist diversity for 410,566 n-grams\n",
      "Total unique n-grams: 917\n",
      "LyricsClassificationExperiment with 11 genres\n",
      "=============================================\n",
      "Train size: 4458 samples\n",
      "Test size: 1138 samples\n",
      "# of features: 917\n",
      "Feature type: Fell-Spohrleder (2014) N-grams (top 100 (per genre and ngram type), min. 20 artists)\n",
      "Model not yet trained.\n",
      "=============================================\n",
      "Output directory: cat5_mock_experiment_fs\n",
      "\n",
      "<class 'pandas.DataFrame'>\n",
      "Training pipeline with fixed parameters...\n",
      "Selected model parameters:\n",
      "  C: 1.000\n",
      "  l1_ratio: 0.500\n",
      "  target_ratio: 3.000\n",
      "============================================================\n",
      "F1 macro: 0.203\n",
      "Precision macro: 0.202\n",
      "Recall macro: 0.202\n",
      "Cohen's kappa: 0.143\n",
      "============================================================\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "alternative rock       0.07      0.09      0.07        46\n",
      "      electronic       0.11      0.12      0.12        90\n",
      "       hard rock       0.09      0.07      0.08        40\n",
      "     heavy metal       0.07      0.09      0.08        56\n",
      "         hip hop       0.57      0.57      0.57        76\n",
      "      indie rock       0.12      0.19      0.15        31\n",
      "            jazz       0.04      0.05      0.04        22\n",
      "           metal       0.31      0.35      0.33       110\n",
      "             pop       0.32      0.38      0.35       239\n",
      "        pop rock       0.08      0.06      0.07        16\n",
      "            rock       0.45      0.32      0.37       412\n",
      "\n",
      "        accuracy                           0.29      1138\n",
      "       macro avg       0.20      0.21      0.20      1138\n",
      "    weighted avg       0.32      0.29      0.30      1138\n",
      "\n",
      "Top 10 coefficients for genre: ALTERNATIVE ROCK\n",
      "i'm (0.500)\n",
      "if you (0.452)\n",
      "around (0.448)\n",
      "were (-0.440)\n",
      "sweet (0.439)\n",
      "you see (-0.431)\n",
      "you down (0.429)\n",
      "for you i (0.419)\n",
      "can you (0.419)\n",
      "all the things (0.418)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: ELECTRONIC\n",
      "me on the (-0.704)\n",
      "ain't (-0.664)\n",
      "i know i'm (0.661)\n",
      "on your (-0.642)\n",
      "you ain't (-0.635)\n",
      "all the (0.596)\n",
      "looking for a (0.581)\n",
      "all (-0.565)\n",
      "you love me (0.558)\n",
      "i don't want (-0.524)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: HARD ROCK\n",
      "it's (0.499)\n",
      "to feel (0.473)\n",
      "feel the (0.444)\n",
      "my soul (-0.392)\n",
      "got me (0.386)\n",
      "i got (0.385)\n",
      "a new (-0.385)\n",
      "in my mind (0.384)\n",
      "you know that (0.383)\n",
      "you go (0.382)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: HEAVY METAL\n",
      "for (0.624)\n",
      "i've (-0.542)\n",
      "fire (0.525)\n",
      "love (-0.518)\n",
      "i guess (0.504)\n",
      "i know it (0.504)\n",
      "in my head (0.464)\n",
      "see (0.461)\n",
      "hard to (0.440)\n",
      "the same (-0.432)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: HIP HOP\n",
      "niggas (0.794)\n",
      "nigga (0.746)\n",
      "die (0.606)\n",
      "i got (0.551)\n",
      "you ain't (0.532)\n",
      "in (0.509)\n",
      "man (0.474)\n",
      "shit (0.472)\n",
      "em (0.470)\n",
      "i know the (0.457)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: INDIE ROCK\n",
      "of death (0.563)\n",
      "oh (0.524)\n",
      "it all (0.509)\n",
      "so i can (0.500)\n",
      "you get (0.458)\n",
      "what you see (0.421)\n",
      "in the (0.416)\n",
      "right (-0.398)\n",
      "ooh ooh ooh (0.393)\n",
      "to be (0.383)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: JAZZ\n",
      "up your (0.630)\n",
      "her (0.555)\n",
      "i'll be there (0.516)\n",
      "i was (-0.468)\n",
      "you take (0.459)\n",
      "on a (0.453)\n",
      "on (-0.393)\n",
      "let the (0.388)\n",
      "so (0.370)\n",
      "i feel like (0.354)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: METAL\n",
      "death (0.629)\n",
      "we are (0.574)\n",
      "oh (-0.541)\n",
      "yeah (-0.497)\n",
      "shit (0.475)\n",
      "all the time (-0.468)\n",
      "dead (0.467)\n",
      "we (-0.462)\n",
      "i have to (0.446)\n",
      "to (0.433)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: POP\n",
      "fuck (-0.748)\n",
      "i don t (-0.713)\n",
      "oh (0.584)\n",
      "no no no (0.524)\n",
      "like that (0.522)\n",
      "wanna (0.514)\n",
      "it to me (-0.503)\n",
      "shit (-0.472)\n",
      "death (-0.464)\n",
      "know what (0.457)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: POP ROCK\n",
      "do you think (0.451)\n",
      "uh (0.392)\n",
      "me i (0.388)\n",
      "out (0.364)\n",
      "i don't wanna (0.364)\n",
      "go on (0.357)\n",
      "the night (0.355)\n",
      "i was (0.355)\n",
      "know that (0.341)\n",
      "next to me (0.339)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: ROCK\n",
      "no no no (-0.633)\n",
      "my mind i (-0.572)\n",
      "gon (-0.560)\n",
      "got (0.458)\n",
      "on my mind (-0.449)\n",
      "and you don't (-0.438)\n",
      "tell me what (-0.425)\n",
      "on my own (-0.422)\n",
      "the one who (-0.422)\n",
      "the fuck (-0.419)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from helpers.LyricsClassficationExperiment import LyricsClassificationExperiment\n",
    "\n",
    "exp_fs = LyricsClassificationExperiment(\n",
    "    corpus=full, \n",
    "    genrecol=\"cat12\",\n",
    "    lyricscol=\"full_lyrics\", \n",
    "    artistcol=\"track.s.firstartist.name\", \n",
    "    output_dir=\"cat5_mock_experiment_fs\",\n",
    "    test_size=0.2,\n",
    "    random_state=42, \n",
    "    subsample_debug=0.05,\n",
    ")\n",
    "exp_fs.compute_fs_ngram_features(min_artists=20, top_n_per_genre_and_ngram=100)\n",
    "fs_features = exp_fs.X_train.keys()\n",
    "print(exp_fs)\n",
    "print(type(exp_fs.X_train))\n",
    "exp_fs.train_fixed_parametrer_logistic_regression()\n",
    "exp_fs.show_model_evaluation()\n",
    "exp_fs.show_top_coefficients_per_genre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b4b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Extracting and scoring n-grams per genre...\n",
      "Extracted 167705 unique bigrams, 380098 unique trigrams\n",
      "Filtered to 2006 n-grams (>= 20 artists, no stopwords)\n",
      "Filtered to 417 n-grams (>= 20 artists, no stopwords)\n",
      "Selected 311 bigrams and 227 trigrams across genres\n",
      "\n",
      "Step 2: Replacing n-grams in corpus...\n",
      "\n",
      "Step 3: Extracting unigrams from replaced corpus...\n",
      "Extracted 1322 unigrams meeting criteria\n",
      "\n",
      "Step 4: Ranking all tokens via TF-IDF...\n",
      "\n",
      "Final vocabulary size: 1216\n",
      "LyricsClassificationExperiment with 11 genres\n",
      "=============================================\n",
      "Train size: 4458 samples\n",
      "Test size: 1138 samples\n",
      "# of features: 1216\n",
      "Feature type: Informed N-grams (top 300 per genre, min. 20 artists)\n",
      "Model not yet trained.\n",
      "=============================================\n",
      "Output directory: cat5_mock_experiment_informed\n",
      "\n",
      "<class 'pandas.DataFrame'>\n",
      "Training pipeline with fixed parameters...\n",
      "Selected model parameters:\n",
      "  C: 1.000\n",
      "  l1_ratio: 0.500\n",
      "  target_ratio: 3.000\n",
      "============================================================\n",
      "F1 macro: 0.212\n",
      "Precision macro: 0.222\n",
      "Recall macro: 0.222\n",
      "Cohen's kappa: 0.158\n",
      "============================================================\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "alternative rock       0.06      0.07      0.06        46\n",
      "      electronic       0.11      0.14      0.13        90\n",
      "       hard rock       0.06      0.05      0.05        40\n",
      "     heavy metal       0.09      0.11      0.10        56\n",
      "         hip hop       0.74      0.57      0.64        76\n",
      "      indie rock       0.07      0.10      0.08        31\n",
      "            jazz       0.08      0.05      0.06        22\n",
      "           metal       0.35      0.44      0.39       110\n",
      "             pop       0.31      0.38      0.34       239\n",
      "        pop rock       0.11      0.06      0.08        16\n",
      "            rock       0.46      0.36      0.40       412\n",
      "\n",
      "        accuracy                           0.31      1138\n",
      "       macro avg       0.22      0.21      0.21      1138\n",
      "    weighted avg       0.34      0.31      0.32      1138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from helpers.LyricsClassficationExperiment import LyricsClassificationExperiment\n",
    "\n",
    "exp_informed = LyricsClassificationExperiment(\n",
    "    corpus=full,\n",
    "    genrecol=\"cat12\",\n",
    "    lyricscol=\"lyrics_lemmatized\",\n",
    "    artistcol=\"track.s.firstartist.name\",\n",
    "    output_dir=\"cat5_mock_experiment_informed\",\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    subsample_debug=0.05,\n",
    ")\n",
    "exp_informed.compute_idiom_ngram_features(min_artists=20, llr_treshold=10, top_n_per_genre=300) # to be similar to FS (2014)\n",
    "print(exp_informed)\n",
    "print(type(exp_informed.X_train))\n",
    "exp_informed.train_fixed_parametrer_logistic_regression()\n",
    "exp_informed.show_model_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a89d9ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 coefficients for genre: ALTERNATIVE ROCK\n",
      "hand (0.458)\n",
      "grace (0.426)\n",
      "distance (0.410)\n",
      "metal (0.407)\n",
      "pretend (0.394)\n",
      "conquer (0.380)\n",
      "world (-0.377)\n",
      "root (0.358)\n",
      "lightning (0.355)\n",
      "moment (-0.346)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: ELECTRONIC\n",
      "your_way (-0.623)\n",
      "man (-0.568)\n",
      "clear (-0.547)\n",
      "believe (-0.518)\n",
      "you_get_to (0.503)\n",
      "you_walk (0.503)\n",
      "family (0.496)\n",
      "cat (0.493)\n",
      "day (0.480)\n",
      "golden (-0.479)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: HARD ROCK\n",
      "madness (0.464)\n",
      "thrill (0.432)\n",
      "that_make (0.412)\n",
      "spot (0.363)\n",
      "leave (0.357)\n",
      "appear (0.353)\n",
      "the_key (0.343)\n",
      "fade (0.335)\n",
      "wheel (0.334)\n",
      "the_song (0.329)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: HEAVY METAL\n",
      "oh_baby (0.560)\n",
      "gonna (0.451)\n",
      "in_life (0.420)\n",
      "the_fear (0.394)\n",
      "attack (0.383)\n",
      "spell (0.364)\n",
      "no_time_to (0.355)\n",
      "fail (0.349)\n",
      "i_keep (-0.332)\n",
      "luck (0.331)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: HIP HOP\n",
      "nigga (0.581)\n",
      "true (0.426)\n",
      "em (0.419)\n",
      "i_get_a (0.408)\n",
      "rap (0.406)\n",
      "shit (0.399)\n",
      "man (0.375)\n",
      "money (0.362)\n",
      "dollar (0.362)\n",
      "let_me (0.357)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: INDIE ROCK\n",
      "hang (0.435)\n",
      "float (0.406)\n",
      "else (0.392)\n",
      "and_give (0.390)\n",
      "certain (0.383)\n",
      "bad (0.381)\n",
      "oh (0.352)\n",
      "heart_and (0.351)\n",
      "dry (0.350)\n",
      "quiet (0.347)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: JAZZ\n",
      "soon (0.707)\n",
      "hoe (0.493)\n",
      "too_late (0.396)\n",
      "really (0.378)\n",
      "smile_and (0.332)\n",
      "around (0.327)\n",
      "moonlight (0.311)\n",
      "one_two_three (0.311)\n",
      "weak (0.302)\n",
      "be_mine (0.288)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: METAL\n",
      "oh_i (-0.605)\n",
      "though (-0.560)\n",
      "slave (0.549)\n",
      "fucking (0.485)\n",
      "ever (-0.469)\n",
      "dead (0.442)\n",
      "curse (0.432)\n",
      "death (0.424)\n",
      "love (-0.417)\n",
      "wound (0.409)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: POP\n",
      "ring (-0.680)\n",
      "be_bear (-0.615)\n",
      "i_get_a (-0.560)\n",
      "right_through (-0.509)\n",
      "dead (-0.503)\n",
      "law (-0.502)\n",
      "battle (-0.498)\n",
      "sink (-0.495)\n",
      "pump (-0.487)\n",
      "flood (-0.453)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: POP ROCK\n",
      "i_guess_i (0.338)\n",
      "i_know_that (0.316)\n",
      "i_want_to (0.293)\n",
      "i_wanna (0.290)\n",
      "oh_i (0.258)\n",
      "someone (0.253)\n",
      "move_on (0.241)\n",
      "think_that_you (0.240)\n",
      "my_face (0.233)\n",
      "paradise (0.230)\n",
      "\n",
      "\n",
      "Top 10 coefficients for genre: ROCK\n",
      "bitch (-0.679)\n",
      "tryna (-0.590)\n",
      "ooh_i (-0.559)\n",
      "e (-0.540)\n",
      "relax (-0.517)\n",
      "gon (-0.508)\n",
      "in_the_sky (-0.495)\n",
      "nigga (-0.454)\n",
      "mmm (-0.448)\n",
      "in_vain (-0.448)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_informed.show_top_coefficients_per_genre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b60b0f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Extracting and scoring n-grams per genre...\n",
      "Extracted 167705 unique bigrams, 380098 unique trigrams\n",
      "Filtered to 548 n-grams (>= 50 artists, no stopwords)\n",
      "Filtered to 51 n-grams (>= 50 artists, no stopwords)\n",
      "Selected 168 bigrams and 39 trigrams across genres\n",
      "\n",
      "Step 2: Replacing n-grams in corpus...\n",
      "\n",
      "Step 3: Extracting unigrams from replaced corpus...\n",
      "Extracted 646 unigrams meeting criteria\n",
      "\n",
      "Step 4: Ranking all tokens via TF-IDF...\n",
      "\n",
      "Final vocabulary size: 837\n"
     ]
    }
   ],
   "source": [
    "from helpers.LyricsClassficationExperiment import LyricsClassificationExperiment\n",
    "\n",
    "exp_topics = LyricsClassificationExperiment(\n",
    "    corpus=full,\n",
    "    genrecol=\"cat12\",\n",
    "    lyricscol=\"lyrics_lemmatized\",\n",
    "    artistcol=\"track.s.firstartist.name\",\n",
    "    output_dir=\"cat5_mock_experiment_informed\",\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    subsample_debug=0.05,\n",
    ")\n",
    "exp_topics.compute_idiom_ngram_features(min_artists=50, llr_threshold=10, top_n_per_genre=300)\n",
    "exp_topics.corpus_train_replaced.to_csv(\"corpus_train_replaced_toR.csv\", index=False)\n",
    "exp_topics.corpus_test_replaced.to_csv(\"corpus_test_replaced_toR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2304b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [06:28<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "# BTM features\n",
    "exp_topics.compute_topics_features(n_topics = (20, 20, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fcc25fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of Topic Model:\n",
      "['a_little' 'a_long' 'a_man' 'a_new' 'a_thousand' 'a_time' 'a_world' 'across_the' 'act' 'afraid' 'ah' 'ahead' 'alive' 'alone' 'along' 'alright' 'always' 'and_get' 'and_i_know' 'and_you_know' 'angel' 'another' 'apart' 'arm' 'around'\n",
      " 'ask' 'away' 'babe' 'baby' 'baby_i' 'baby_you' 'back' 'back_to' 'bad' 'bag' 'be_bear' 'be_come' 'be_go' 'be_mine' 'be_right' 'be_wait' 'bear' 'beat' 'beautiful' 'become' 'bed' 'begin' 'behind' 'believe' 'belong' 'best' 'beyond' 'big'\n",
      " 'bird' 'bitch' 'black' 'bleed' 'blind' 'blood' 'blow' 'blue' 'body' 'bone' 'book' 'bout' 'boy' 'brain' 'break' 'break_the' 'breath' 'breathe' 'bright' 'bring' 'bring_me' 'broken' 'brother' 'build' 'burn' 'burning' 'buy' 'call'\n",
      " 'call_me' 'can_feel' 'can_take' 'cannot' 'car' 'care' 'carry' 'cast' 'catch' 'cause' 'cause_i' 'cause_you' 'chain' 'chance' 'change' 'check' 'child' 'choose' 'city' 'clean' 'clear' 'close' 'clothes' 'cloud' 'cold' 'come' 'come_on'\n",
      " 'come_to' 'control' 'cool' 'cover' 'crash' 'crawl' 'crazy' 'cross' 'cry' 'cut' 'damn' 'dance' 'dark' 'dawn' 'day' 'dead' 'deal' 'dear' 'death' 'deep' 'demon' 'deny' 'desire' 'destiny' 'devil' 'die' 'different' 'dog' 'doin' 'door'\n",
      " 'dream' 'drink' 'drive' 'drop' 'drown' 'drug' 'dry' 'ear' 'earth' 'easy' 'eat' 'else' 'em' 'empty' 'end' 'enough' 'escape' 'even' 'ever' 'every' 'everybody' 'everyone' 'everything' 'everything_i' 'everywhere' 'evil' 'eye' 'face' 'fade'\n",
      " 'fail' 'faith' 'fall' 'family' 'far' 'far_away' 'fast' 'fate' 'father' 'fear' 'feel' 'feel_like' 'feel_the' 'feelin' 'feeling' 'fell' 'felt' 'fight' 'fill' 'final' 'find' 'find_a' 'fine' 'fire' 'first' 'fit' 'five' 'flame' 'flesh'\n",
      " 'flow' 'fly' 'follow' 'fool' 'foot' 'force' 'forever' 'forget' 'four' 'free' 'friend' 'front' 'fuck' 'fuckin' 'full_of' 'funny' 'game' 'get' 'get_a' 'get_it' 'get_me' 'get_the' 'get_to' 'get_your' 'gettin' 'ghost' 'girl' 'give'\n",
      " 'give_me' 'give_up' 'give_you' 'go' 'go_on' 'go_to' 'god' 'goin' 'gold' 'golden' 'gon' 'gonna' 'gonna_be' 'good' 'gotta' 'grace' 'great' 'green' 'ground' 'grow' 'gun' 'guy' 'hair' 'hand' 'hang' 'happen' 'happy' 'hard' 'hard_to' 'hate'\n",
      " 'have_come' 'he_say' 'head' 'heal' 'hear' 'hear_the' 'heart' 'heart_and' 'heat' 'heaven' 'hell' 'help' 'hey' 'hey_hey' 'hide' 'high' 'hit' 'hit_the' 'hold' 'hold_me' 'hold_on' 'hold_you' 'home' 'hop' 'hope' 'hot' 'hour' 'house' 'huh'\n",
      " 'human' 'hundred' 'hurt' 'i_believe' 'i_come' 'i_ever' 'i_feel' 'i_find' 'i_get' 'i_get_a' 'i_get_to' 'i_give' 'i_go' 'i_gotta' 'i_hear' 'i_keep' 'i_know' 'i_know_i' 'i_know_that' 'i_know_you' 'i_let' 'i_like' 'i_look' 'i_love_you'\n",
      " 'i_make' 'i_need' 'i_never' 'i_put' 'i_remember' 'i_say' 'i_see' 'i_see_you' 'i_still' 'i_take' 'i_tell' 'i_think' 'i_try_to' 'i_wanna' 'i_wanna_be' 'i_want' 'i_want_to' 'i_wish' 'i_would' 'in_love' 'in_the_dark' 'in_the_sky' 'in_time'\n",
      " 'inside' 'it_feel' 'it_right' 'it_take' 'just_like' 'keep' 'keep_it' 'key' 'kid' 'kill' 'king' 'kiss' 'knee' 'know' 'know_if' 'know_that' 'know_that_i' 'know_what' 'lady' 'land' 'last' 'late' 'laugh' 'law' 'lay' 'lead' 'learn' 'leave'\n",
      " 'leave_me' 'leave_to' 'less' 'let' 'let_go' 'let_it' 'let_me' 'let_the' 'let_you' 'lie' 'life' 'light' 'like' 'like_a' 'like_i' 'like_it' 'like_that' 'like_the' 'like_this' 'like_you' 'line' 'listen' 'little' 'live' 'live_in' 'livin'\n",
      " 'living' 'lock' 'lonely' 'long' 'look' 'look_at' 'look_for' 'lookin' 'lord' 'lose' 'lose_my' 'loud' 'love' 'love_and' 'love_be' 'love_me' 'love_you' 'lover' 'low' 'mad' 'magic' 'make' 'make_a' 'make_it' 'make_me' 'make_you' 'mama'\n",
      " 'man' 'man_i' 'many' 'matter' 'may' 'maybe' 'me_baby' 'me_cause' 'mean' 'meet' 'memory' 'men' 'might' 'mile' 'mind' 'mine' 'mirror' 'miss' 'mistake' 'moment' 'money' 'mountain' 'move' 'much' 'music' 'my_dream' 'my_eye' 'my_face'\n",
      " 'my_foot' 'my_hand' 'my_head' 'my_heart' 'my_heart_be' 'my_life' 'my_love' 'my_mind' 'my_name' 'my_soul' 'my_time' 'name' 'need' 'never' 'never_be' 'new' 'next' 'nigga' 'night' 'night_and' 'no_one' 'nobody' 'nothin' 'nothing'\n",
      " 'nothing_to' 'nowhere' 'of_life' 'of_time' 'oh' 'oh_i' 'oh_no' 'oh_oh' 'oh_oh_oh' 'oh_yeah' 'oh_you' 'okay' 'old' 'one' 'ooh' 'ooh_ooh' 'open' 'outside' 'pack' 'pain' 'party' 'pass' 'past' 'path' 'pay' 'peace' 'people' 'phone' 'pick'\n",
      " 'piece' 'place' 'plan' 'play' 'please' 'power' 'pray' 'pretend' 'pretty' 'promise' 'prove' 'pull' 'push' 'put' 'race' 'rain' 'raise' 'reach' 'read' 'ready_to' 'real' 'really' 'reason' 'red' 'remain' 'remember' 'rest' 'return' 'ride'\n",
      " 'right' 'ring' 'rise' 'river' 'road' 'rock' 'roll' 'room' 'round' 'rule' 'run' 'sad' 'safe' 'save' 'saw' 'say' 'say_i' 'say_that' 'scar' 'scream' 'search_for' 'secret' 'see' 'see_the' 'see_you' 'seek' 'seem' 'seem_to' 'self' 'sell'\n",
      " 'send' 'sense' 'set' 'shadow' 'shake' 'shall' 'shame' 'shin' 'shine' 'shit' 'shoot' 'shot' 'show' 'show_you' 'sick' 'side' 'sight' 'sign' 'silence' 'silent' 'sin' 'since' 'sing' 'sit' 'skin' 'sky' 'sleep' 'slow' 'small' 'smile' 'smoke'\n",
      " 'so_far' 'so_long' 'so_much' 'somebody' 'someone' 'somethin' 'something' 'sometimes' 'son' 'song' 'soon' 'sorrow' 'sorry' 'soul' 'sound' 'space' 'speak' 'spend' 'spirit' 'spread' 'stand' 'star' 'start' 'state' 'stay' 'steal' 'step'\n",
      " 'stick' 'still' 'stone' 'stop' 'storm' 'story' 'straight' 'stranger' 'street' 'strike' 'strong' 'style' 'sun' 'sure' 'survive' 'sweet' 'take' 'take_a' 'take_it' 'take_me' 'take_my' 'take_the' 'take_you' 'talk' 'talk_to' 'talkin'\n",
      " 'taste' 'tear' 'tell' 'tell_me' 'tell_you' 'the_air' 'the_beat' 'the_city' 'the_dark' 'the_day' 'the_door' 'the_earth' 'the_edge' 'the_end' 'the_end_of' 'the_eye' 'the_fire' 'the_future' 'the_game' 'the_ground' 'the_last' 'the_light'\n",
      " 'the_moon' 'the_morning' 'the_night' 'the_one' 'the_pain' 'the_past' 'the_people' 'the_power' 'the_rain' 'the_shadow' 'the_sky' 'the_sound' 'the_street' 'the_sun' 'the_thing' 'the_time' 'the_truth' 'the_wall' 'the_water' 'the_way'\n",
      " 'the_whole' 'the_wind' 'the_word' 'the_world' 'they_say' 'thing' 'think' 'think_of' 'think_that' 'this_time' 'this_world' 'though' 'thought' 'three' 'throw' 'tight' 'til' 'till' 'time' 'time_i' 'time_to' 'to_come' 'to_feel' 'to_fight'\n",
      " 'to_find' 'to_get' 'to_go' 'to_hear' 'to_know' 'to_love' 'to_make' 'to_say' 'to_see' 'to_take' 'to_tell' 'today' 'together' 'tomorrow' 'tongue' 'tonight' 'too_late' 'too_much' 'top' 'touch' 'town' 'track' 'train' 'tree' 'trouble'\n",
      " 'true' 'truth' 'try' 'try_to' 'tryna' 'turn' 'turn_to' 'two' 'u' 'uh' 'understand' 'upon' 'use' 'use_to' 'voice' 'wait' 'wait_for' 'wake' 'wake_up' 'walk' 'wall' 'wanna' 'want' 'want_to' 'want_you' 'war' 'warm' 'waste' 'watch' 'wave'\n",
      " 'way' 'way_i' 'way_to' 'we_get' 'we_know' 'weak' 'wear' 'well' 'well_i' 'whatever' 'wheel' 'white' 'whole' 'wild' 'will_never' 'win' 'wind' 'wing' 'wish' 'wish_i' 'within' 'without' 'woah' 'woman' 'wonder' 'word' 'work' 'world' 'worry'\n",
      " 'worth' 'would' 'would_you' 'wound' 'write' 'wrong' 'ya' 'yeah' 'yeah_i' 'yeah_yeah' 'yeah_yeah_yeah' 'year' 'yes' 'yesterday' 'yet' 'yo' 'you_come' 'you_feel' 'you_find' 'you_get' 'you_give' 'you_go' 'you_hear' 'you_know' 'you_know_i'\n",
      " 'you_let' 'you_like' 'you_look' 'you_make' 'you_need' 'you_never' 'you_really' 'you_say' 'you_see' 'you_take' 'you_tell_me' 'you_think' 'you_turn' 'you_walk' 'you_wanna' 'you_want' 'young' 'your_eye' 'your_face' 'your_hand' 'your_head'\n",
      " 'your_heart' 'your_life' 'your_love' 'your_mind' 'your_name' 'your_soul']\n",
      "Topic Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ['keep',\n",
       "  'well',\n",
       "  'u',\n",
       "  'try_to',\n",
       "  'nothing',\n",
       "  'your_heart',\n",
       "  'gonna',\n",
       "  'away',\n",
       "  'roll',\n",
       "  'deep'],\n",
       " 1: ['nigga',\n",
       "  'fuck',\n",
       "  'shit',\n",
       "  'bitch',\n",
       "  'like',\n",
       "  'yo',\n",
       "  'get',\n",
       "  'em',\n",
       "  'i_get',\n",
       "  'yeah'],\n",
       " 2: ['find',\n",
       "  'ever',\n",
       "  'forever',\n",
       "  'inside',\n",
       "  'run',\n",
       "  'kill',\n",
       "  'life',\n",
       "  'always',\n",
       "  'stop',\n",
       "  'die'],\n",
       " 3: ['time',\n",
       "  'keep',\n",
       "  'day',\n",
       "  'since',\n",
       "  'like',\n",
       "  'remember',\n",
       "  'bad',\n",
       "  'live',\n",
       "  'ever',\n",
       "  'never'],\n",
       " 4: ['king',\n",
       "  'come',\n",
       "  'u',\n",
       "  'find',\n",
       "  'maybe',\n",
       "  'never',\n",
       "  'go',\n",
       "  'dream',\n",
       "  'be_come',\n",
       "  'thing'],\n",
       " 5: ['bout',\n",
       "  'talkin',\n",
       "  'worry',\n",
       "  'life',\n",
       "  'people',\n",
       "  'get',\n",
       "  'think',\n",
       "  'stop',\n",
       "  'shit',\n",
       "  'money'],\n",
       " 6: ['fight',\n",
       "  'go',\n",
       "  'right',\n",
       "  'another',\n",
       "  'cause',\n",
       "  'last',\n",
       "  'one',\n",
       "  'get',\n",
       "  'back',\n",
       "  'chance'],\n",
       " 7: ['get',\n",
       "  'back',\n",
       "  'train',\n",
       "  'go',\n",
       "  'one',\n",
       "  'inside',\n",
       "  'girl',\n",
       "  'wait',\n",
       "  'home',\n",
       "  'lose'],\n",
       " 8: ['i_love_you',\n",
       "  'love_you',\n",
       "  'word',\n",
       "  'remember',\n",
       "  'my_heart',\n",
       "  'yeah_yeah',\n",
       "  'my_name',\n",
       "  'uh',\n",
       "  'say_i',\n",
       "  'way_to'],\n",
       " 9: ['love',\n",
       "  'go',\n",
       "  'know',\n",
       "  'never',\n",
       "  'back',\n",
       "  'learn',\n",
       "  'alone',\n",
       "  'girl',\n",
       "  'i_know',\n",
       "  'wrong'],\n",
       " 10: ['drop',\n",
       "  'tear',\n",
       "  'ready_to',\n",
       "  'i_get_a',\n",
       "  'get',\n",
       "  'little',\n",
       "  'face',\n",
       "  'every',\n",
       "  'roll',\n",
       "  'go'],\n",
       " 11: ['love',\n",
       "  'like',\n",
       "  'never',\n",
       "  'someone',\n",
       "  'know',\n",
       "  'need',\n",
       "  'really',\n",
       "  'go',\n",
       "  'think',\n",
       "  'heart'],\n",
       " 12: ['like_a',\n",
       "  'fall',\n",
       "  'u',\n",
       "  'light',\n",
       "  'dream',\n",
       "  'come',\n",
       "  'fly',\n",
       "  'rise',\n",
       "  'high',\n",
       "  'the_sky'],\n",
       " 13: ['enough',\n",
       "  'get',\n",
       "  'too_much',\n",
       "  'talk',\n",
       "  'i_know',\n",
       "  'i_like',\n",
       "  'long',\n",
       "  'oh',\n",
       "  'baby',\n",
       "  'time'],\n",
       " 14: ['wait',\n",
       "  'sit',\n",
       "  'run',\n",
       "  'they_say',\n",
       "  'wait_for',\n",
       "  'line',\n",
       "  'never',\n",
       "  'come',\n",
       "  'burn',\n",
       "  'car'],\n",
       " 15: ['get',\n",
       "  'tonight',\n",
       "  'time',\n",
       "  'fall',\n",
       "  'right',\n",
       "  'night',\n",
       "  'cause',\n",
       "  'look_for',\n",
       "  'oh',\n",
       "  'well'],\n",
       " 16: ['cry',\n",
       "  'love',\n",
       "  'still',\n",
       "  'dream',\n",
       "  'tear',\n",
       "  'know',\n",
       "  'never',\n",
       "  'u',\n",
       "  'come',\n",
       "  'try'],\n",
       " 17: ['gonna',\n",
       "  'make',\n",
       "  'tell_me',\n",
       "  'nothing',\n",
       "  'you_know',\n",
       "  'thing',\n",
       "  'get',\n",
       "  'one',\n",
       "  'go',\n",
       "  'blue'],\n",
       " 18: ['kill',\n",
       "  'white',\n",
       "  'men',\n",
       "  'war',\n",
       "  'man',\n",
       "  'gun',\n",
       "  'die',\n",
       "  'fight',\n",
       "  'yeah',\n",
       "  'stand'],\n",
       " 19: ['u',\n",
       "  'your_love',\n",
       "  'turn',\n",
       "  'tell_me',\n",
       "  'something',\n",
       "  'i_feel',\n",
       "  'real',\n",
       "  'back',\n",
       "  'keep',\n",
       "  'i_need'],\n",
       " 20: ['oh_oh_oh',\n",
       "  'oh_oh',\n",
       "  'oh',\n",
       "  'little',\n",
       "  'alone',\n",
       "  'woah',\n",
       "  'lie',\n",
       "  'ah',\n",
       "  'girl',\n",
       "  'the_end_of'],\n",
       " 21: ['get',\n",
       "  'gonna',\n",
       "  'i_get',\n",
       "  'i_want',\n",
       "  'wanna',\n",
       "  'baby',\n",
       "  'get_it',\n",
       "  'cause_i',\n",
       "  'yeah',\n",
       "  'you_get'],\n",
       " 22: ['god',\n",
       "  'war',\n",
       "  'die',\n",
       "  'dead',\n",
       "  'like',\n",
       "  'lord',\n",
       "  'love',\n",
       "  'blood',\n",
       "  'cry',\n",
       "  'the_world'],\n",
       " 23: ['time',\n",
       "  'away',\n",
       "  'blow',\n",
       "  'go',\n",
       "  'hard',\n",
       "  'roll',\n",
       "  'say',\n",
       "  'many',\n",
       "  'dream',\n",
       "  'still'],\n",
       " 24: ['run',\n",
       "  'away',\n",
       "  'you_hear',\n",
       "  'call',\n",
       "  'ever',\n",
       "  'well',\n",
       "  'hide',\n",
       "  'baby',\n",
       "  'the_sun',\n",
       "  'my_name'],\n",
       " 25: ['tonight',\n",
       "  'high',\n",
       "  'oh',\n",
       "  'baby',\n",
       "  'i_wanna',\n",
       "  'gonna',\n",
       "  'girl',\n",
       "  'i_get',\n",
       "  'my_love',\n",
       "  'the_night'],\n",
       " 26: ['gonna',\n",
       "  'take_it',\n",
       "  'hell',\n",
       "  'go',\n",
       "  'mad',\n",
       "  'slow',\n",
       "  'away',\n",
       "  'make_it',\n",
       "  'take',\n",
       "  'back'],\n",
       " 27: ['life',\n",
       "  'line',\n",
       "  'free',\n",
       "  'way',\n",
       "  'gonna',\n",
       "  'oh',\n",
       "  'live',\n",
       "  'day',\n",
       "  'people',\n",
       "  'world'],\n",
       " 28: ['angel',\n",
       "  'talk_to',\n",
       "  'my_heart',\n",
       "  'play',\n",
       "  'find',\n",
       "  'i_see_you',\n",
       "  'eye',\n",
       "  'close',\n",
       "  'gonna',\n",
       "  'no_one'],\n",
       " 29: ['one',\n",
       "  'two',\n",
       "  'step',\n",
       "  'three',\n",
       "  'love',\n",
       "  'back',\n",
       "  'four',\n",
       "  'turn',\n",
       "  'man',\n",
       "  'lover'],\n",
       " 30: ['never',\n",
       "  'gonna',\n",
       "  'cry',\n",
       "  'die',\n",
       "  'get',\n",
       "  'always',\n",
       "  'guy',\n",
       "  'go_to',\n",
       "  'high',\n",
       "  'wanna'],\n",
       " 31: ['play',\n",
       "  'people',\n",
       "  'game',\n",
       "  'long',\n",
       "  'say',\n",
       "  'song',\n",
       "  'talk',\n",
       "  'home',\n",
       "  'try',\n",
       "  'dance'],\n",
       " 32: ['beautiful',\n",
       "  'see',\n",
       "  'world',\n",
       "  'give',\n",
       "  'you_go',\n",
       "  'child',\n",
       "  'oh_yeah',\n",
       "  'like',\n",
       "  'go',\n",
       "  'tell_me'],\n",
       " 33: ['everybody',\n",
       "  'reason',\n",
       "  'even',\n",
       "  'one',\n",
       "  'though',\n",
       "  'drink',\n",
       "  'run',\n",
       "  'i_tell',\n",
       "  'oh',\n",
       "  'go'],\n",
       " 34: ['love',\n",
       "  'wrong',\n",
       "  'bad',\n",
       "  'friend',\n",
       "  'take',\n",
       "  'i_get',\n",
       "  'good',\n",
       "  'go',\n",
       "  'ever',\n",
       "  'right'],\n",
       " 35: ['long',\n",
       "  'go',\n",
       "  'till',\n",
       "  'stay',\n",
       "  'day',\n",
       "  'yeah',\n",
       "  'forever',\n",
       "  'gonna',\n",
       "  'love',\n",
       "  'miss'],\n",
       " 36: ['place',\n",
       "  'leave',\n",
       "  'you_tell_me',\n",
       "  'memory',\n",
       "  'come',\n",
       "  'always',\n",
       "  'remember',\n",
       "  'far_away',\n",
       "  'well',\n",
       "  'start'],\n",
       " 37: ['stay',\n",
       "  'away',\n",
       "  'way',\n",
       "  'time',\n",
       "  'love',\n",
       "  'day',\n",
       "  'change',\n",
       "  'new',\n",
       "  'like_a',\n",
       "  'fall'],\n",
       " 38: ['nothing',\n",
       "  'thing',\n",
       "  'go',\n",
       "  'leave_to',\n",
       "  'real',\n",
       "  'leave',\n",
       "  'say',\n",
       "  'like',\n",
       "  'know',\n",
       "  'reason'],\n",
       " 39: ['alive',\n",
       "  'live',\n",
       "  'my_life',\n",
       "  'keep',\n",
       "  'i_know',\n",
       "  'light',\n",
       "  'inside',\n",
       "  'i_wanna_be',\n",
       "  'something',\n",
       "  'kill'],\n",
       " 40: ['baby',\n",
       "  'oh',\n",
       "  'your_love',\n",
       "  'cause',\n",
       "  'ever',\n",
       "  'gonna',\n",
       "  'i_feel',\n",
       "  'change',\n",
       "  'love_you',\n",
       "  'feel'],\n",
       " 41: ['get',\n",
       "  'no_one',\n",
       "  'gonna',\n",
       "  'ah',\n",
       "  'baby',\n",
       "  'beat',\n",
       "  'foot',\n",
       "  'talk',\n",
       "  'remember',\n",
       "  'fuck'],\n",
       " 42: ['away',\n",
       "  'get',\n",
       "  'today',\n",
       "  'day',\n",
       "  'run',\n",
       "  'the_light',\n",
       "  'low',\n",
       "  'i_feel',\n",
       "  'high',\n",
       "  'feel'],\n",
       " 43: ['let_me',\n",
       "  'wanna',\n",
       "  'see_you',\n",
       "  'go',\n",
       "  'know',\n",
       "  'i_never',\n",
       "  'i_want_to',\n",
       "  'never',\n",
       "  'baby',\n",
       "  'die'],\n",
       " 44: ['in_love',\n",
       "  'lover',\n",
       "  'love',\n",
       "  'another',\n",
       "  'fell',\n",
       "  'go',\n",
       "  'star',\n",
       "  'cross',\n",
       "  'girl',\n",
       "  'too_much'],\n",
       " 45: ['u',\n",
       "  'save',\n",
       "  'set',\n",
       "  'free',\n",
       "  'fall',\n",
       "  'no_one',\n",
       "  'soul',\n",
       "  'inside',\n",
       "  'get',\n",
       "  'cause'],\n",
       " 46: ['u',\n",
       "  'get',\n",
       "  'fly',\n",
       "  'like',\n",
       "  'home',\n",
       "  'stay',\n",
       "  'love',\n",
       "  'alone',\n",
       "  'sing',\n",
       "  'wing'],\n",
       " 47: ['home',\n",
       "  'the_last',\n",
       "  'love',\n",
       "  'wait',\n",
       "  'baby',\n",
       "  'lord',\n",
       "  'last',\n",
       "  'oh',\n",
       "  'free',\n",
       "  'set'],\n",
       " 48: ['like',\n",
       "  'back',\n",
       "  'yeah',\n",
       "  'right',\n",
       "  'fuck',\n",
       "  'turn',\n",
       "  'thing',\n",
       "  'work',\n",
       "  'lie',\n",
       "  'say'],\n",
       " 49: ['wild',\n",
       "  'hang',\n",
       "  'night',\n",
       "  'love',\n",
       "  'get_it',\n",
       "  'get',\n",
       "  'time',\n",
       "  'smile',\n",
       "  'every',\n",
       "  'the_night'],\n",
       " 50: ['love',\n",
       "  'lie',\n",
       "  'live',\n",
       "  'never',\n",
       "  'come',\n",
       "  'die',\n",
       "  'oh_oh',\n",
       "  'show',\n",
       "  'still',\n",
       "  'way'],\n",
       " 51: ['you_get',\n",
       "  'like',\n",
       "  'get_a',\n",
       "  'something',\n",
       "  'star',\n",
       "  'gold',\n",
       "  'love',\n",
       "  'old',\n",
       "  'give_me',\n",
       "  'want'],\n",
       " 52: ['right',\n",
       "  'oh',\n",
       "  'back',\n",
       "  'love',\n",
       "  'i_get',\n",
       "  'call',\n",
       "  'tight',\n",
       "  'well',\n",
       "  'just_like',\n",
       "  'yeah'],\n",
       " 53: ['go',\n",
       "  'still',\n",
       "  'never',\n",
       "  'gonna',\n",
       "  'one',\n",
       "  'lie',\n",
       "  'wrong',\n",
       "  'thing',\n",
       "  'i_think',\n",
       "  'dead'],\n",
       " 54: ['home',\n",
       "  'oh',\n",
       "  'call',\n",
       "  'old',\n",
       "  'woman',\n",
       "  'another',\n",
       "  'one',\n",
       "  'come',\n",
       "  'way',\n",
       "  'town'],\n",
       " 55: ['side',\n",
       "  'live_in',\n",
       "  'town',\n",
       "  'the_dark',\n",
       "  'stranger',\n",
       "  'die',\n",
       "  'i_wanna',\n",
       "  'lie',\n",
       "  'care',\n",
       "  'ride'],\n",
       " 56: ['i_believe',\n",
       "  'believe',\n",
       "  'spirit',\n",
       "  'u',\n",
       "  'love',\n",
       "  'long',\n",
       "  'move',\n",
       "  'oh',\n",
       "  'get',\n",
       "  'enough'],\n",
       " 57: ['man',\n",
       "  'woman',\n",
       "  'man_i',\n",
       "  'a_man',\n",
       "  'real',\n",
       "  'want',\n",
       "  'oh',\n",
       "  'right',\n",
       "  'babe',\n",
       "  'say'],\n",
       " 58: ['girl',\n",
       "  'like',\n",
       "  'come',\n",
       "  'keep_it',\n",
       "  'tell',\n",
       "  'baby',\n",
       "  'cause',\n",
       "  'real',\n",
       "  'around',\n",
       "  'back'],\n",
       " 59: ['good',\n",
       "  'wonder',\n",
       "  'well',\n",
       "  'back',\n",
       "  'bring',\n",
       "  'say',\n",
       "  'go_to',\n",
       "  'go',\n",
       "  'time',\n",
       "  'around'],\n",
       " 60: ['yeah',\n",
       "  'hey',\n",
       "  'man',\n",
       "  'shit',\n",
       "  'right',\n",
       "  'go',\n",
       "  'get',\n",
       "  'check',\n",
       "  'people',\n",
       "  'whole'],\n",
       " 61: ['forever',\n",
       "  'stay',\n",
       "  'around',\n",
       "  'life',\n",
       "  'never',\n",
       "  'away',\n",
       "  'open',\n",
       "  'u',\n",
       "  'one',\n",
       "  'come_on'],\n",
       " 62: ['touch',\n",
       "  'like',\n",
       "  'reach',\n",
       "  'space',\n",
       "  'high',\n",
       "  'come_on',\n",
       "  'place',\n",
       "  'fly',\n",
       "  'one',\n",
       "  'the_sky'],\n",
       " 63: ['away',\n",
       "  'love',\n",
       "  'always',\n",
       "  'change',\n",
       "  'go',\n",
       "  'everything',\n",
       "  'enough',\n",
       "  'run',\n",
       "  'time',\n",
       "  'know'],\n",
       " 64: ['girl',\n",
       "  'fuck',\n",
       "  'even',\n",
       "  'yeah',\n",
       "  'well',\n",
       "  'good',\n",
       "  'start',\n",
       "  'ooh',\n",
       "  'see',\n",
       "  'nigga'],\n",
       " 65: ['beat',\n",
       "  'like_a',\n",
       "  'dream',\n",
       "  'my_heart_be',\n",
       "  'body',\n",
       "  'lay',\n",
       "  'evil',\n",
       "  'dead',\n",
       "  'run',\n",
       "  'blue'],\n",
       " 66: ['say',\n",
       "  'wanna',\n",
       "  'girl',\n",
       "  'yeah',\n",
       "  'like_i',\n",
       "  'right',\n",
       "  'know',\n",
       "  'oh',\n",
       "  'cause',\n",
       "  'never'],\n",
       " 67: ['forever',\n",
       "  'ever',\n",
       "  'never',\n",
       "  'come',\n",
       "  'nothing',\n",
       "  'together',\n",
       "  'go',\n",
       "  'may',\n",
       "  'keep',\n",
       "  'last'],\n",
       " 68: ['get',\n",
       "  'oh',\n",
       "  'lie',\n",
       "  'dead',\n",
       "  'back',\n",
       "  'say',\n",
       "  'little',\n",
       "  'live',\n",
       "  'hold',\n",
       "  'beat'],\n",
       " 69: ['many',\n",
       "  'come',\n",
       "  'tell_me',\n",
       "  'free',\n",
       "  'man',\n",
       "  'voice',\n",
       "  'way',\n",
       "  'home',\n",
       "  'hand',\n",
       "  'great'],\n",
       " 70: ['hey',\n",
       "  'hey_hey',\n",
       "  'little',\n",
       "  'look_at',\n",
       "  'oh',\n",
       "  'say',\n",
       "  'go',\n",
       "  'good',\n",
       "  'like_a',\n",
       "  'away'],\n",
       " 71: ['one',\n",
       "  'say',\n",
       "  'go',\n",
       "  'stop',\n",
       "  'never',\n",
       "  'another',\n",
       "  'back',\n",
       "  'find',\n",
       "  'long',\n",
       "  'put'],\n",
       " 72: ['sound',\n",
       "  'round',\n",
       "  'turn',\n",
       "  'little',\n",
       "  'around',\n",
       "  'town',\n",
       "  'the_sound',\n",
       "  'nothing',\n",
       "  'year',\n",
       "  'u'],\n",
       " 73: ['wait',\n",
       "  'away',\n",
       "  'put',\n",
       "  'blow',\n",
       "  'go',\n",
       "  'oh',\n",
       "  'day',\n",
       "  'cold',\n",
       "  'time',\n",
       "  'the_fire'],\n",
       " 74: ['break',\n",
       "  'home',\n",
       "  'fall',\n",
       "  'alone',\n",
       "  'away',\n",
       "  'heart',\n",
       "  'lonely',\n",
       "  'cause',\n",
       "  'my_heart',\n",
       "  'cry'],\n",
       " 75: ['u',\n",
       "  'get',\n",
       "  'we_get',\n",
       "  'way',\n",
       "  'right',\n",
       "  'away',\n",
       "  'come',\n",
       "  'like_a',\n",
       "  'go',\n",
       "  'cause'],\n",
       " 76: ['you_never',\n",
       "  'get',\n",
       "  'dream',\n",
       "  'no_one',\n",
       "  'i_see',\n",
       "  'i_know',\n",
       "  'know',\n",
       "  'ever',\n",
       "  'someone',\n",
       "  'somebody'],\n",
       " 77: ['never',\n",
       "  'away',\n",
       "  'break',\n",
       "  'nothing',\n",
       "  'back',\n",
       "  'still',\n",
       "  'lose',\n",
       "  'love',\n",
       "  'take',\n",
       "  'leave'],\n",
       " 78: ['life',\n",
       "  'human',\n",
       "  'end',\n",
       "  'never',\n",
       "  'one',\n",
       "  'please',\n",
       "  'pain',\n",
       "  'oh',\n",
       "  'hold',\n",
       "  'understand'],\n",
       " 79: ['time',\n",
       "  'long',\n",
       "  'a_long',\n",
       "  'way',\n",
       "  'come',\n",
       "  'home',\n",
       "  'around',\n",
       "  'gonna_be',\n",
       "  'know',\n",
       "  'may'],\n",
       " 80: ['ah',\n",
       "  'oh',\n",
       "  'hard',\n",
       "  'go',\n",
       "  'party',\n",
       "  'rock',\n",
       "  'show',\n",
       "  'start',\n",
       "  'long',\n",
       "  'hey_hey'],\n",
       " 81: ['ride',\n",
       "  'one',\n",
       "  'go',\n",
       "  'fly',\n",
       "  'real',\n",
       "  'high',\n",
       "  'time',\n",
       "  'far',\n",
       "  'hell',\n",
       "  'eye'],\n",
       " 82: ['burn',\n",
       "  'let_it',\n",
       "  'the_night',\n",
       "  'inside',\n",
       "  'away',\n",
       "  'baby',\n",
       "  'like',\n",
       "  'come',\n",
       "  'take',\n",
       "  'fall'],\n",
       " 83: ['nothing',\n",
       "  'new',\n",
       "  'stop',\n",
       "  'something',\n",
       "  'still',\n",
       "  'night',\n",
       "  'try',\n",
       "  'crazy',\n",
       "  'even',\n",
       "  'though'],\n",
       " 84: ['ooh_ooh',\n",
       "  'dream',\n",
       "  'sleep',\n",
       "  'way',\n",
       "  'home',\n",
       "  'oh_i',\n",
       "  'lie',\n",
       "  'high',\n",
       "  'long',\n",
       "  'close'],\n",
       " 85: ['gotta',\n",
       "  'get',\n",
       "  'back',\n",
       "  'something',\n",
       "  'hand',\n",
       "  'good',\n",
       "  'get_to',\n",
       "  'find',\n",
       "  'stand',\n",
       "  'another'],\n",
       " 86: ['bring',\n",
       "  'death',\n",
       "  'life',\n",
       "  'lose',\n",
       "  'fall',\n",
       "  'fear',\n",
       "  'rise',\n",
       "  'dead',\n",
       "  'one',\n",
       "  'light'],\n",
       " 87: ['night',\n",
       "  'light',\n",
       "  'eye',\n",
       "  'cold',\n",
       "  'heart',\n",
       "  'blood',\n",
       "  'turn',\n",
       "  'break',\n",
       "  'the_light',\n",
       "  'never'],\n",
       " 88: ['word',\n",
       "  'u',\n",
       "  'tell',\n",
       "  'go',\n",
       "  'time',\n",
       "  'say',\n",
       "  'tell_me',\n",
       "  'i_know',\n",
       "  'know',\n",
       "  'you_get'],\n",
       " 89: ['burn',\n",
       "  'blood',\n",
       "  'death',\n",
       "  'come',\n",
       "  'fear',\n",
       "  'fire',\n",
       "  'dead',\n",
       "  'lie',\n",
       "  'black',\n",
       "  'war'],\n",
       " 90: ['way',\n",
       "  'one',\n",
       "  'new',\n",
       "  'fall',\n",
       "  'like',\n",
       "  'long',\n",
       "  'god',\n",
       "  'light',\n",
       "  'face',\n",
       "  'may'],\n",
       " 91: ['i_wanna',\n",
       "  'fight',\n",
       "  'wanna',\n",
       "  'touch',\n",
       "  'start',\n",
       "  'you_wanna',\n",
       "  'get',\n",
       "  'burn',\n",
       "  'i_want',\n",
       "  'say'],\n",
       " 92: ['look',\n",
       "  'oh',\n",
       "  'face',\n",
       "  'day',\n",
       "  'back',\n",
       "  'thing',\n",
       "  'night',\n",
       "  'one',\n",
       "  'last',\n",
       "  'away'],\n",
       " 93: ['heaven',\n",
       "  'right',\n",
       "  'like',\n",
       "  'help',\n",
       "  'good',\n",
       "  'still',\n",
       "  'every',\n",
       "  'touch',\n",
       "  'ooh',\n",
       "  'u'],\n",
       " 94: ['take_me',\n",
       "  'ya',\n",
       "  'i_need',\n",
       "  'baby',\n",
       "  'oh',\n",
       "  'gonna',\n",
       "  'like',\n",
       "  'top',\n",
       "  'run',\n",
       "  'bring_me'],\n",
       " 95: ['care',\n",
       "  'oh',\n",
       "  'get',\n",
       "  'well',\n",
       "  'take',\n",
       "  'mind',\n",
       "  'you_get',\n",
       "  'you_know',\n",
       "  'run',\n",
       "  'really'],\n",
       " 96: ['song',\n",
       "  'sing',\n",
       "  'love',\n",
       "  'oh',\n",
       "  'come_on',\n",
       "  'play',\n",
       "  'get',\n",
       "  'sweet',\n",
       "  'gonna',\n",
       "  'happy'],\n",
       " 97: ['rock',\n",
       "  'roll',\n",
       "  'everybody',\n",
       "  'ooh',\n",
       "  'come_on',\n",
       "  'good',\n",
       "  'dog',\n",
       "  'u',\n",
       "  'make',\n",
       "  'town'],\n",
       " 98: ['story',\n",
       "  'late',\n",
       "  'wake',\n",
       "  'break_the',\n",
       "  'law',\n",
       "  'one',\n",
       "  'meet',\n",
       "  'u',\n",
       "  'bag',\n",
       "  'tear'],\n",
       " 99: ['ooh',\n",
       "  'yeah',\n",
       "  'hey',\n",
       "  'ooh_ooh',\n",
       "  'oh_yeah',\n",
       "  'oh_oh',\n",
       "  'babe',\n",
       "  'come',\n",
       "  'oh',\n",
       "  'ah'],\n",
       " 100: ['go',\n",
       "  'river',\n",
       "  'cry',\n",
       "  'i_go',\n",
       "  'well',\n",
       "  'tear',\n",
       "  'back',\n",
       "  'away',\n",
       "  'baby',\n",
       "  'know'],\n",
       " 101: ['shake',\n",
       "  'you_get',\n",
       "  'get',\n",
       "  'baby_you',\n",
       "  'break',\n",
       "  'you_know',\n",
       "  'baby',\n",
       "  'call',\n",
       "  'rock',\n",
       "  'yeah'],\n",
       " 102: ['black',\n",
       "  'eye',\n",
       "  'white',\n",
       "  'blue',\n",
       "  'man',\n",
       "  'world',\n",
       "  'still',\n",
       "  'oh',\n",
       "  'little',\n",
       "  'sky'],\n",
       " 103: ['love',\n",
       "  'feel',\n",
       "  'real',\n",
       "  'dream',\n",
       "  'thing',\n",
       "  'time',\n",
       "  'make',\n",
       "  'take',\n",
       "  'i_feel',\n",
       "  'girl'],\n",
       " 104: ['baby',\n",
       "  'oh',\n",
       "  'smile',\n",
       "  'city',\n",
       "  'cry',\n",
       "  'yeah',\n",
       "  'life',\n",
       "  'give',\n",
       "  'leave_me',\n",
       "  'feel'],\n",
       " 105: ['i_get',\n",
       "  'cause',\n",
       "  'stop',\n",
       "  'like',\n",
       "  'girl',\n",
       "  'one',\n",
       "  'start',\n",
       "  'ever',\n",
       "  'beat',\n",
       "  'right'],\n",
       " 106: ['hate',\n",
       "  'kill',\n",
       "  'blood',\n",
       "  'let',\n",
       "  'death',\n",
       "  'like',\n",
       "  'head',\n",
       "  'long',\n",
       "  'gonna',\n",
       "  'i_feel'],\n",
       " 107: ['big',\n",
       "  'get',\n",
       "  'well',\n",
       "  'life',\n",
       "  'let_me',\n",
       "  'new',\n",
       "  'get_a',\n",
       "  'every',\n",
       "  'i_get',\n",
       "  'round'],\n",
       " 108: ['together',\n",
       "  'lay',\n",
       "  'love',\n",
       "  'stand',\n",
       "  'forever',\n",
       "  'in_the_dark',\n",
       "  'one',\n",
       "  'come',\n",
       "  'back',\n",
       "  'hand'],\n",
       " 109: ['one',\n",
       "  'like',\n",
       "  'get_a',\n",
       "  'something',\n",
       "  'lonely',\n",
       "  'put',\n",
       "  'you_hear',\n",
       "  'world',\n",
       "  'sing',\n",
       "  'friend'],\n",
       " 110: ['i_think',\n",
       "  'shame',\n",
       "  'change',\n",
       "  'a_little',\n",
       "  'maybe',\n",
       "  'tell_me',\n",
       "  'crazy',\n",
       "  'little',\n",
       "  'hang',\n",
       "  'faith'],\n",
       " 111: ['get',\n",
       "  'nigga',\n",
       "  'like',\n",
       "  'back',\n",
       "  'go',\n",
       "  'say',\n",
       "  'move',\n",
       "  'shit',\n",
       "  'bitch',\n",
       "  'take'],\n",
       " 112: ['lie',\n",
       "  'die',\n",
       "  'dream',\n",
       "  'lose',\n",
       "  'every',\n",
       "  'go',\n",
       "  'oh',\n",
       "  'yeah',\n",
       "  'word',\n",
       "  'last'],\n",
       " 113: ['u',\n",
       "  'die',\n",
       "  'go',\n",
       "  'make',\n",
       "  'fall',\n",
       "  'still',\n",
       "  'say',\n",
       "  'the_day',\n",
       "  'come',\n",
       "  'time'],\n",
       " 114: ['party',\n",
       "  'hard',\n",
       "  'yeah_yeah_yeah',\n",
       "  'yeah',\n",
       "  'go',\n",
       "  'ah',\n",
       "  'yeah_yeah',\n",
       "  'dance',\n",
       "  'tonight',\n",
       "  'go_to'],\n",
       " 115: ['oh',\n",
       "  'woah',\n",
       "  'give',\n",
       "  'seem_to',\n",
       "  'the_pain',\n",
       "  'tear',\n",
       "  'drown',\n",
       "  'wave',\n",
       "  'year',\n",
       "  'lord'],\n",
       " 116: ['hot',\n",
       "  'get',\n",
       "  'love',\n",
       "  'like',\n",
       "  'around',\n",
       "  'i_know',\n",
       "  'hard',\n",
       "  'sweet',\n",
       "  'enough',\n",
       "  'like_a'],\n",
       " 117: ['hold_on',\n",
       "  'get',\n",
       "  'life',\n",
       "  'alone',\n",
       "  'together',\n",
       "  'still',\n",
       "  'love',\n",
       "  'the_night',\n",
       "  'forever',\n",
       "  'remember'],\n",
       " 118: ['uh',\n",
       "  'huh',\n",
       "  'ooh',\n",
       "  'yeah',\n",
       "  'oh',\n",
       "  'yeah_yeah',\n",
       "  'like',\n",
       "  'might',\n",
       "  'bright',\n",
       "  'ah'],\n",
       " 119: ['go',\n",
       "  'round',\n",
       "  'home',\n",
       "  'let_it',\n",
       "  'right',\n",
       "  'way',\n",
       "  'the_world',\n",
       "  'time_to',\n",
       "  'back',\n",
       "  'turn'],\n",
       " 120: ['nigga',\n",
       "  'trouble',\n",
       "  'get',\n",
       "  'run',\n",
       "  'boy',\n",
       "  'always',\n",
       "  'let',\n",
       "  'ooh',\n",
       "  'little',\n",
       "  'wing'],\n",
       " 121: ['money',\n",
       "  'bag',\n",
       "  'work',\n",
       "  'go',\n",
       "  'run',\n",
       "  'get',\n",
       "  'make',\n",
       "  'i_get',\n",
       "  'yeah',\n",
       "  'take_me'],\n",
       " 122: ['come',\n",
       "  'like',\n",
       "  'oh',\n",
       "  'tonight',\n",
       "  'last',\n",
       "  'i_know',\n",
       "  'kiss',\n",
       "  'mind',\n",
       "  'land',\n",
       "  'promise'],\n",
       " 123: ['call',\n",
       "  'sleep',\n",
       "  'close',\n",
       "  'turn',\n",
       "  'i_feel',\n",
       "  'get',\n",
       "  'say',\n",
       "  'i_hear',\n",
       "  'i_get',\n",
       "  'leave'],\n",
       " 124: ['alone',\n",
       "  'leave_me',\n",
       "  'cry',\n",
       "  'please',\n",
       "  'home',\n",
       "  'life',\n",
       "  'i_get',\n",
       "  'you_see',\n",
       "  'i_think',\n",
       "  'stop'],\n",
       " 125: ['the_world',\n",
       "  'leave',\n",
       "  'still',\n",
       "  'run',\n",
       "  'look',\n",
       "  'place',\n",
       "  'nowhere',\n",
       "  'fall',\n",
       "  'live',\n",
       "  'life'],\n",
       " 126: ['get',\n",
       "  'come',\n",
       "  'tell_me',\n",
       "  'baby',\n",
       "  'live',\n",
       "  'well',\n",
       "  'yeah',\n",
       "  'life',\n",
       "  'everything',\n",
       "  'want_to'],\n",
       " 127: ['light',\n",
       "  'bright',\n",
       "  'sun',\n",
       "  'come',\n",
       "  'shine',\n",
       "  'shin',\n",
       "  'the_sun',\n",
       "  'tonight',\n",
       "  'my_life',\n",
       "  'star'],\n",
       " 128: ['dance',\n",
       "  'the_light',\n",
       "  'hot',\n",
       "  'right',\n",
       "  'really',\n",
       "  'in_the_dark',\n",
       "  'one',\n",
       "  'the_sun',\n",
       "  'oh',\n",
       "  'tonight'],\n",
       " 129: ['boy',\n",
       "  'bad',\n",
       "  'girl',\n",
       "  'man',\n",
       "  'i_know',\n",
       "  'real',\n",
       "  'get',\n",
       "  'you_get',\n",
       "  'miss',\n",
       "  'cause'],\n",
       " 130: ['you_like',\n",
       "  'you_want',\n",
       "  'begin',\n",
       "  'to_love',\n",
       "  'kiss',\n",
       "  'be_mine',\n",
       "  'ask',\n",
       "  'tell_me',\n",
       "  'i_would',\n",
       "  'love'],\n",
       " 131: ['go',\n",
       "  'cause',\n",
       "  'life',\n",
       "  'make',\n",
       "  'u',\n",
       "  'keep',\n",
       "  'leave',\n",
       "  'know',\n",
       "  'stand',\n",
       "  'work'],\n",
       " 132: ['come_on',\n",
       "  'get',\n",
       "  'yeah',\n",
       "  'thing',\n",
       "  'baby',\n",
       "  'get_a',\n",
       "  'yo',\n",
       "  'you_get',\n",
       "  'good',\n",
       "  'everybody'],\n",
       " 133: ['baby',\n",
       "  'oh',\n",
       "  'babe',\n",
       "  'love_me',\n",
       "  'around',\n",
       "  'come',\n",
       "  'you_know',\n",
       "  'away',\n",
       "  'love_you',\n",
       "  'ooh'],\n",
       " 134: ['change',\n",
       "  'love',\n",
       "  'nobody',\n",
       "  'no_one',\n",
       "  'learn',\n",
       "  'go',\n",
       "  'it_take',\n",
       "  'care',\n",
       "  'thing',\n",
       "  'ever'],\n",
       " 135: ['come',\n",
       "  'get_me',\n",
       "  'save',\n",
       "  'space',\n",
       "  'hard_to',\n",
       "  'you_come',\n",
       "  'take_me',\n",
       "  'far_away',\n",
       "  'though',\n",
       "  'brain'],\n",
       " 136: ['life',\n",
       "  'good',\n",
       "  'yeah',\n",
       "  'livin',\n",
       "  'i_get',\n",
       "  'bad',\n",
       "  'still',\n",
       "  'live',\n",
       "  'run',\n",
       "  'like_a'],\n",
       " 137: ['dream',\n",
       "  'like',\n",
       "  'stand',\n",
       "  'come',\n",
       "  'never',\n",
       "  'follow',\n",
       "  'lose',\n",
       "  'call',\n",
       "  'end',\n",
       "  'boy'],\n",
       " 138: ['tell_me',\n",
       "  'oh',\n",
       "  'cry',\n",
       "  'one',\n",
       "  'love',\n",
       "  'right',\n",
       "  'sweet',\n",
       "  'till',\n",
       "  'laugh',\n",
       "  'find'],\n",
       " 139: ['go',\n",
       "  'i_get',\n",
       "  'oh',\n",
       "  'stranger',\n",
       "  'light',\n",
       "  'like_a',\n",
       "  'man',\n",
       "  'home',\n",
       "  'come',\n",
       "  'thought'],\n",
       " 140: ['home',\n",
       "  'close',\n",
       "  'open',\n",
       "  'away',\n",
       "  'go',\n",
       "  'back',\n",
       "  'keep',\n",
       "  'drive',\n",
       "  'eye',\n",
       "  'come'],\n",
       " 141: ['one',\n",
       "  'thing',\n",
       "  'heart',\n",
       "  'always',\n",
       "  'fall',\n",
       "  'may',\n",
       "  'every',\n",
       "  'come',\n",
       "  'love',\n",
       "  'true'],\n",
       " 142: ['gonna',\n",
       "  'get',\n",
       "  'good',\n",
       "  'like',\n",
       "  'i_feel',\n",
       "  'yeah',\n",
       "  'home',\n",
       "  'run',\n",
       "  'time',\n",
       "  'blue'],\n",
       " 143: ['back',\n",
       "  'home',\n",
       "  'right',\n",
       "  'turn',\n",
       "  'i_get',\n",
       "  'put',\n",
       "  'time',\n",
       "  'hold',\n",
       "  'yes',\n",
       "  'fight'],\n",
       " 144: ['high',\n",
       "  'walk',\n",
       "  'fly',\n",
       "  'get',\n",
       "  'low',\n",
       "  'talk',\n",
       "  'blue',\n",
       "  'stop',\n",
       "  'go',\n",
       "  'lay'],\n",
       " 145: ['stop',\n",
       "  'get',\n",
       "  'say',\n",
       "  'gonna',\n",
       "  'move',\n",
       "  'yeah',\n",
       "  'live',\n",
       "  'know',\n",
       "  'thing',\n",
       "  'you_think'],\n",
       " 146: ['girl',\n",
       "  'fall',\n",
       "  'everything',\n",
       "  'something',\n",
       "  'you_say',\n",
       "  'every',\n",
       "  'back',\n",
       "  'see',\n",
       "  'say',\n",
       "  'remember'],\n",
       " 147: ['fall',\n",
       "  'breathe',\n",
       "  'go',\n",
       "  'like',\n",
       "  'oh',\n",
       "  'line',\n",
       "  'keep',\n",
       "  'try_to',\n",
       "  'time',\n",
       "  'rain'],\n",
       " 148: ['alright',\n",
       "  'one',\n",
       "  'night',\n",
       "  'gonna_be',\n",
       "  'good',\n",
       "  'i_know',\n",
       "  'man',\n",
       "  'day',\n",
       "  'girl',\n",
       "  'right'],\n",
       " 149: ['my_love',\n",
       "  'tonight',\n",
       "  'let',\n",
       "  'always',\n",
       "  'inside',\n",
       "  'deep',\n",
       "  'forever',\n",
       "  'your_heart',\n",
       "  'listen',\n",
       "  'come_to']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Vocabulary of Topic Model:\")\n",
    "print(exp_topics.topic_model.vocabulary_)\n",
    "print(\"Topic Words:\")\n",
    "exp_topics.topic_model.get_topic_words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89eac48f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Buffer dtype mismatch, expected 'long' but got 'long long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# exp_topics.topics_extractor.get_topic_score(exp_topics.corpus_train_replaced)\u001b[39;00m\n",
      "\u001b[1;32m----> 2\u001b[0m \u001b[43mexp_topics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoherence_\u001b[49m\n",
      "\n",
      "File \u001b[1;32mN:\\Materialien\\Promotion\\LyricsGenreRecognition\\.venv\\Lib\\site-packages\\bitermplus\\_api.py:372\u001b[0m, in \u001b[0;36mBTMClassifier.coherence_\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    370\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Topic coherence scores.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    371\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoherence_\u001b[49m\n",
      "\n",
      "File \u001b[1;32msrc/bitermplus/_btm.pyx:698\u001b[0m, in \u001b[0;36mbitermplus._btm.BTM.coherence_.__get__\u001b[1;34m()\u001b[0m\n",
      "\n",
      "File \u001b[1;32msrc/bitermplus/_metrics.pyx:95\u001b[0m, in \u001b[0;36mbitermplus._metrics.coherence\u001b[1;34m()\u001b[0m\n",
      "\n",
      "File \u001b[1;32msrc/bitermplus/_metrics.pyx:154\u001b[0m, in \u001b[0;36mbitermplus._metrics.coherence\u001b[1;34m()\u001b[0m\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'long' but got 'long long'"
     ]
    }
   ],
   "source": [
    "# exp_topics.topics_extractor.get_topic_score(exp_topics.corpus_train_replaced)\n",
    "exp_topics.topic_model.coherence_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6e42a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pipeline with fixed parameters...\n",
      "Selected model parameters:\n",
      "  C: 1.000\n",
      "  l1_ratio: 0.500\n",
      "  target_ratio: 3.000\n",
      "============================================================\n",
      "F1 macro: 0.222\n",
      "Precision macro: 0.235\n",
      "Recall macro: 0.235\n",
      "Cohen's kappa: 0.223\n",
      "============================================================\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "alternative rock       0.18      0.07      0.10        46\n",
      "      electronic       0.19      0.11      0.14        90\n",
      "       hard rock       0.00      0.00      0.00        40\n",
      "     heavy metal       0.12      0.07      0.09        56\n",
      "         hip hop       0.70      0.61      0.65        76\n",
      "      indie rock       0.11      0.03      0.05        31\n",
      "            jazz       0.00      0.00      0.00        22\n",
      "           metal       0.48      0.58      0.53       110\n",
      "             pop       0.36      0.55      0.43       239\n",
      "        pop rock       0.00      0.00      0.00        16\n",
      "            rock       0.45      0.47      0.46       412\n",
      "\n",
      "        accuracy                           0.40      1138\n",
      "       macro avg       0.24      0.23      0.22      1138\n",
      "    weighted avg       0.36      0.40      0.37      1138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "exp_topics.train_fixed_parametrer_logistic_regression()\n",
    "exp_topics.show_model_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17ec8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pipeline with fixed parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# perform STM in R and load and set X_train and X_test\n",
    "X_train = pd.read_csv('X_train_stm.csv')\n",
    "X_test = pd.read_csv(\"X_test_stm.csv\")\n",
    "\n",
    "# bad practice, but ok for now\n",
    "exp_topics.X_train = X_train\n",
    "exp_topics.X_test = X_test\n",
    "\n",
    "exp_topics.train_fixed_parametrer_logistic_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17dc13f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model parameters:\n",
      "  C: 1.000\n",
      "  l1_ratio: 0.500\n",
      "  target_ratio: 3.000\n",
      "============================================================\n",
      "F1 macro: 0.184\n",
      "Precision macro: 0.201\n",
      "Recall macro: 0.201\n",
      "Cohen's kappa: 0.145\n",
      "============================================================\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "alternative rock       0.07      0.07      0.07        46\n",
      "      electronic       0.09      0.10      0.09        90\n",
      "       hard rock       0.06      0.05      0.05        40\n",
      "     heavy metal       0.06      0.07      0.07        56\n",
      "         hip hop       0.77      0.43      0.55        76\n",
      "      indie rock       0.00      0.00      0.00        31\n",
      "            jazz       0.00      0.00      0.00        22\n",
      "           metal       0.39      0.37      0.38       110\n",
      "             pop       0.35      0.45      0.39       239\n",
      "        pop rock       0.00      0.00      0.00        16\n",
      "            rock       0.43      0.40      0.41       412\n",
      "\n",
      "        accuracy                           0.32      1138\n",
      "       macro avg       0.20      0.18      0.18      1138\n",
      "    weighted avg       0.33      0.32      0.32      1138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_topics.show_model_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2a961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting and scoring n-grams per genre...\n",
      "Extracted 167705 unique bigrams, 380098 unique trigrams, 480992 unique quadgrams\n",
      "Filtered to 639 n-grams (>= 20 artists, >= 40 tracks, no stopwords)\n",
      "Filtered to 91 n-grams (>= 20 artists, >= 40 tracks, no stopwords)\n",
      "Filtered to 2 n-grams (>= 20 artists, >= 40 tracks, no stopwords)\n",
      "Selected 585 bigrams, 91 trigrams, and 2 quadgrams across genres\n",
      "\n",
      "Replacing n-grams in corpus...\n",
      "\n",
      "Ranking tokens via TF-IDF per n-gram type...\n",
      "\n",
      "Final vocabulary size: 487\n"
     ]
    }
   ],
   "source": [
    "from helpers.LyricsClassficationExperiment import LyricsClassificationExperiment\n",
    "\n",
    "exp_topics = LyricsClassificationExperiment(\n",
    "    corpus=full,\n",
    "    genrecol=\"cat12\",\n",
    "    lyricscol=\"lyrics_lemmatized\",\n",
    "    artistcol=\"track.s.firstartist.name\",\n",
    "    output_dir=\"cat5_mock_experiment_informed\",\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    subsample_debug=0.05,\n",
    ")\n",
    "exp_topics.compute_idiom_ngram_features(\n",
    "    min_artists=20, min_tracks=40, llr_threshold=10, top_n_per_ngram_pergenre=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c751f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered tokens (>=3 underscores): 93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a_little_bit',\n",
       " 'a_lot_of',\n",
       " 'all_the_thing',\n",
       " 'all_the_time',\n",
       " 'and_i_know',\n",
       " 'and_you_know',\n",
       " 'as_long_a',\n",
       " 'back_to_the',\n",
       " 'be_the_one',\n",
       " 'but_i_know',\n",
       " 'close_your_eye',\n",
       " 'find_a_way',\n",
       " 'i_can_feel',\n",
       " 'i_can_see',\n",
       " 'i_feel_the',\n",
       " 'i_get_a',\n",
       " 'i_get_the',\n",
       " 'i_get_to',\n",
       " 'i_give_you',\n",
       " 'i_just_wanna',\n",
       " 'i_know_i',\n",
       " 'i_know_it',\n",
       " 'i_know_that',\n",
       " 'i_know_what',\n",
       " 'i_know_you',\n",
       " 'i_love_you',\n",
       " 'i_need_a',\n",
       " 'i_need_to',\n",
       " 'i_need_you',\n",
       " 'i_see_the',\n",
       " 'i_see_you',\n",
       " 'i_tell_you',\n",
       " 'i_think_i',\n",
       " 'i_try_to',\n",
       " 'i_use_to',\n",
       " 'i_wanna_be',\n",
       " 'i_want_to',\n",
       " 'i_want_you',\n",
       " 'if_you_want',\n",
       " 'in_love_with',\n",
       " 'in_my_eye',\n",
       " 'in_my_head',\n",
       " 'in_my_heart',\n",
       " 'in_my_mind',\n",
       " 'in_the_air',\n",
       " 'in_the_dark',\n",
       " 'in_the_end',\n",
       " 'in_the_morning',\n",
       " 'in_the_night',\n",
       " 'in_the_sky',\n",
       " 'in_your_eye',\n",
       " 'know_how_to',\n",
       " 'know_that_i',\n",
       " 'know_that_you',\n",
       " 'know_what_i',\n",
       " 'look_at_me',\n",
       " 'my_heart_be',\n",
       " 'of_the_night',\n",
       " 'of_the_world',\n",
       " 'oh_oh_oh',\n",
       " 'oh_oh_oh_oh',\n",
       " 'on_my_mind',\n",
       " 'tell_me_that',\n",
       " 'tell_me_what',\n",
       " 'the_end_of',\n",
       " 'the_sound_of',\n",
       " 'the_thing_that',\n",
       " 'the_way_i',\n",
       " 'the_way_that',\n",
       " 'the_way_you',\n",
       " 'the_world_be',\n",
       " 'to_make_it',\n",
       " 'to_see_you',\n",
       " 'use_to_be',\n",
       " 'wait_for_the',\n",
       " 'want_to_be',\n",
       " 'want_you_to',\n",
       " 'what_i_want',\n",
       " 'what_you_want',\n",
       " 'yeah_yeah_yeah',\n",
       " 'yeah_yeah_yeah_yeah',\n",
       " 'you_get_to',\n",
       " 'you_give_me',\n",
       " 'you_know_i',\n",
       " 'you_know_that',\n",
       " 'you_know_what',\n",
       " 'you_know_you',\n",
       " 'you_love_me',\n",
       " 'you_make_me',\n",
       " 'you_say_you',\n",
       " 'you_tell_me',\n",
       " 'you_try_to',\n",
       " 'you_want_to']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exp_topics.ngram_extractor.vocabulary\n",
    "\n",
    "# filter quadgrams (containing three underscores) from vocab\n",
    "filtered_vocab = [\n",
    "    token for token in exp_topics.ngram_extractor.vocabulary\n",
    "    if token.count('_') >= 2\n",
    "]\n",
    "print(f\"Filtered tokens (>=3 underscores): {len(filtered_vocab)}\")\n",
    "filtered_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f29f346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pipeline with fixed parameters...\n",
      "Selected model parameters:\n",
      "  C: 1.000\n",
      "  l1_ratio: 0.500\n",
      "  target_ratio: 3.000\n",
      "============================================================\n",
      "F1 macro: 0.140\n",
      "Precision macro: 0.139\n",
      "Recall macro: 0.139\n",
      "Cohen's kappa: 0.073\n",
      "============================================================\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "alternative rock       0.08      0.09      0.09        46\n",
      "      electronic       0.12      0.13      0.12        90\n",
      "       hard rock       0.04      0.03      0.03        40\n",
      "     heavy metal       0.09      0.11      0.10        56\n",
      "         hip hop       0.27      0.36      0.31        76\n",
      "      indie rock       0.02      0.03      0.03        31\n",
      "            jazz       0.03      0.05      0.04        22\n",
      "           metal       0.20      0.19      0.19       110\n",
      "             pop       0.30      0.34      0.32       239\n",
      "        pop rock       0.00      0.00      0.00        16\n",
      "            rock       0.38      0.28      0.32       412\n",
      "\n",
      "        accuracy                           0.24      1138\n",
      "       macro avg       0.14      0.14      0.14      1138\n",
      "    weighted avg       0.26      0.24      0.24      1138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\Materialien\\Promotion\\LyricsGenreRecognition\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "exp_topics.train_fixed_parametrer_logistic_regression()\n",
    "exp_topics.show_model_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3074f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 macro: 0.086\n",
      "Precision macro: 0.087\n",
      "Recall macro: 0.087\n",
      "Cohen's kappa: -0.001\n"
     ]
    }
   ],
   "source": [
    "exp_topics.show_random_baseline_evaluation()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
